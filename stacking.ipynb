{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stacking.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "mUKhe-vC-LIw",
        "QPypOQs6GY_Q",
        "i4yUkcdkblT-",
        "Xq18Jw09HuJ4",
        "rXIi1j3XHnzz",
        "yfN4T87FDEln"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstroBoy1/santander/blob/master/stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mUKhe-vC-LIw"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "***"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "79f9790e-8214-4555-dc6a-a75fe80ce123",
        "id": "3JM3uflR-LIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install vecstack\n",
        "!pip install catboost"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vecstack\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/1d/7665736f10f3e15af9d51b4e73c16c8ea798e339f6bf4eadfa1dee77c672/vecstack-0.3.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from vecstack) (0.20.3)\n",
            "Building wheels for collected packages: vecstack\n",
            "  Building wheel for vecstack (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/35/6d/ca/bce17942bcf7c267b13c97c9c95e2f0ecf0b42160e6074f448\n",
            "Successfully built vecstack\n",
            "Installing collected packages: vecstack\n",
            "Successfully installed vecstack-0.3.0\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/62/b442e8d747e8a34ac8a981f7a4ff717c1f887aedb42c3f670660bda41af5/catboost-0.13.1-cp36-none-manylinux1_x86_64.whl (60.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 60.1MB 708kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.14.6)\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.6)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2018.9)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uC48gUBv-LIX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d6a9b7d6-c2ba-4ce5-b763-56c696f78c22"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import time\n",
        "import statistics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from vecstack import stacking\n",
        "from vecstack import StackingTransformer\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import re \n",
        "np.random.seed(0) # ensure reproducibility\n",
        "np.set_printoptions(suppress = True)\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import log_loss\n",
        "# Models\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Stacking\n",
        "from vecstack import stacking\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Input, Flatten, Dropout, BatchNormalization, GaussianNoise\n",
        "from keras import callbacks\n",
        "import keras.backend as K\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from mlxtend.feature_selection import ColumnSelector\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "39861344-d442-4908-8700-8586f3fe46d1",
        "id": "IETJszVE-LIH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "O0bwvFih-LHi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_fn = '/content/gdrive/My Drive/santander_data/train.csv'\n",
        "valid_fn = '/content/gdrive/My Drive/santander_data/test.csv'\n",
        "pred_fn = '/content/gdrive/My Drive/santander_data/submission12.csv'\n",
        "train_data_df = pd.read_csv(train_fn)\n",
        "test_data_df = pd.read_csv(valid_fn)\n",
        "train_data_x = train_data_df.drop(columns=[\"ID_code\", \"target\"]).values\n",
        "train_data_y = train_data_df[\"target\"].values\n",
        "test_data_x = test_data_df.drop(columns=[\"ID_code\"]).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPypOQs6GY_Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ]
    },
    {
      "metadata": {
        "id": "EXs3lkQhGY_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_classes = 2\n",
        "length = 1000\n",
        "X, y = train_data_x[:length], train_data_y[:length]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "save_directory = '/content/gdrive/My Drive/santander_results/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uCWZkCB2r79M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LGB, XGB, Catboost params"
      ]
    },
    {
      "metadata": {
        "id": "7J2mCU9Orz0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lgb_params = {\n",
        "    'bagging_freq': 5,\n",
        "    'bagging_fraction': 0.335,\n",
        "    'boost_from_average':'false',\n",
        "    'boost': 'gbdt',\n",
        "    'feature_fraction': 0.041,\n",
        "    'learning_rate': 0.0083,\n",
        "    'max_depth': -1,\n",
        "    'metric':'auc',\n",
        "    'min_data_in_leaf': 80,\n",
        "    'min_sum_hessian_in_leaf': 10.0,\n",
        "    'num_leaves': 13,\n",
        "    'num_threads': 8,\n",
        "    'tree_learner': 'serial',\n",
        "    'objective': 'binary', \n",
        "    'verbosity': -1}\n",
        "\n",
        "xgb_params = {'tree_method': 'hist',\n",
        " 'objective': 'binary:logistic',\n",
        " 'eval_metric': 'auc',\n",
        " 'learning_rate': 0.0936165921314771,\n",
        " 'max_depth': 2,\n",
        " 'colsample_bytree': 0.3561271102144279,\n",
        " 'subsample': 0.8246604621518232,\n",
        " 'min_child_weight': 53,\n",
        " 'gamma': 9.943467991283027,\n",
        " 'silent': 1,\n",
        "}\n",
        "\n",
        "catboost_params = {'subsample':0.36, #rawdata 0.5  ×2 0.45 ×3 0.36\n",
        "                            'loss_function':'Logloss',\n",
        "                           'random_strength':0,\n",
        "                           'max_depth':3,\n",
        "                           'eval_metric':\"AUC\",\n",
        "                           'learning_rate':0.02,\n",
        "                           #'iterations':60000,\n",
        "                           'iterations':100,\n",
        "                           #class_weights=[1,2],\n",
        "                           'bootstrap_type':'Bernoulli',\n",
        "                           #rsm=0.045,\n",
        "                            'l2_leaf_reg':0.3,\n",
        "                           #'task_type':\"GPU\",\n",
        "                           'random_seed':432013,\n",
        "                           'od_type':\"Iter\",\n",
        "                           'border_count':128,\n",
        "                           'logging_level':'Silent'\n",
        "                           #has_time= True \n",
        "                  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JX1D2qJEJBex",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Wrappers"
      ]
    },
    {
      "metadata": {
        "id": "D_vyzYCmJEbc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class WrapLGB(LGBMClassifier):\n",
        "    \"\"\"This is template for user-defined class wrapper.\n",
        "    Use this template to pass any ``fit`` and ``predict`` arguments.\n",
        "    \"\"\"\n",
        "    def fit(self, X, y):\n",
        "        X_tr, X_val, y_tr, y_val = train_test_split(X, y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42)\n",
        "        return super(WrapLGB, self).fit(X_tr, y_tr, \n",
        "                                        early_stopping_rounds=5, \n",
        "                                        eval_set=[(X_val, y_val)], \n",
        "                                        eval_metric='auc', verbose=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return super(WrapLGB, self).predict(X, \n",
        "               num_iteration=self.best_iteration_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i4yUkcdkblT-"
      },
      "cell_type": "markdown",
      "source": [
        "# NN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Xz6CKnuTblSs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def auc(y_true, y_pred):\n",
        "    \"\"\"ROC AUC metric for both binary and multiclass classification.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : 1d numpy array\n",
        "        True class labels\n",
        "    y_pred : 2d numpy array\n",
        "        Predicted probabilities for each class\n",
        "    \"\"\"\n",
        "    ohe = OneHotEncoder(sparse=False)\n",
        "    y_true = ohe.fit_transform(y_true.reshape(-1, 1))\n",
        "    auc_score = roc_auc_score(y_true, y_pred)\n",
        "    return auc_score\n",
        "\n",
        "# LOGGER\n",
        "class Logger(callbacks.Callback):\n",
        "    def __init__(self, out_path='./', patience=10, lr_patience=3, out_fn='', log_fn=''):\n",
        "        self.auc = 0\n",
        "        self.path = out_path\n",
        "        self.fn = out_fn\n",
        "        self.patience = patience\n",
        "        self.lr_patience = lr_patience\n",
        "        self.no_improve = 0\n",
        "        self.no_improve_lr = 0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        cv_pred = self.model.predict(self.validation_data[0], batch_size=1024)\n",
        "        cv_true = self.validation_data[1]\n",
        "        auc_val = roc_auc_score(cv_true, cv_pred)\n",
        "        if self.auc < auc_val:\n",
        "            self.no_improve = 0\n",
        "            self.no_improve_lr = 0\n",
        "            print(\"Epoch %s - best AUC: %s\" % (epoch, round(auc_val, 4)))\n",
        "            self.auc = auc_val\n",
        "            self.model.save(self.path + self.fn, overwrite=True)\n",
        "        else:\n",
        "            self.no_improve += 1\n",
        "            self.no_improve_lr += 1\n",
        "            print(\"Epoch %s - current AUC: %s\" % (epoch, round(auc_val, 4)))\n",
        "            if self.no_improve >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "            if self.no_improve_lr >= self.lr_patience:\n",
        "                lr = float(K.get_value(self.model.optimizer.lr))\n",
        "                K.set_value(self.model.optimizer.lr, 0.75*lr)\n",
        "                print(\"Setting lr to {}\".format(0.75*lr))\n",
        "                self.no_improve_lr = 0\n",
        "\n",
        "        return\n",
        "\n",
        "# MODEL DEF\n",
        "def dnn():\n",
        "#     inp = Input(shape=(200, 1))\n",
        "#     d1 = Dense(16, activation='relu')(inp)\n",
        "#     fl = Flatten()(d1)\n",
        "#     preds = Dense(1, activation='sigmoid')(fl)\n",
        "#     model = Model(inputs=inp, outputs=preds)\n",
        "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "logger = Logger(patience=10, out_path=save_directory, out_fn='cv_{}.h5')\n",
        "#nn_params = {'nb_epoch':32, 'batch_size':256, 'callbacks':[logger], 'verbose':1}\n",
        "nn_params = {'epochs':32, 'batch_size':256, 'verbose':1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "McU0f1Ge8Acc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stacking Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "WMzNY7Bz8Cp-",
        "colab_type": "code",
        "outputId": "d02f820a-5b1d-42c5-9212-b6185ba5b422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "# Specify steps of Pipeline\n",
        "\n",
        "# Same paramaters to models, but different subfeatures by:\n",
        "# 1. Select a random number for the number of features to select\n",
        "# 2. Randomly select that many features\n",
        "num_subsets = 1\n",
        "subsets = []\n",
        "features = list(range(200))\n",
        "number = list(range(1, 201))\n",
        "pipe_models_1 = []\n",
        "for num in range(num_subsets):\n",
        "    num_features = np.random.choice(number, size=1)[0]\n",
        "    subset = np.random.choice(features, size=num_features, replace=False, p=None)\n",
        "    subsets.append(subset)\n",
        "    cl1 = ('gnb' + str(num), make_pipeline(ColumnSelector(cols=tuple(subset)), GaussianNB()))\n",
        "    cl2 = ('xgb' + str(num), make_pipeline(ColumnSelector(cols=tuple(subset)), XGBClassifier(**xgb_params)))\n",
        "    cl3 = ('lgbm' + str(num), make_pipeline(ColumnSelector(cols=tuple(subset)), WrapLGB(**lgb_params)))\n",
        "    cl4 = ('cb' + str(num), make_pipeline(ColumnSelector(cols=tuple(subset)), CatBoostClassifier(**catboost_params)))\n",
        "    pipe_models_1.append(cl1)\n",
        "    pipe_models_1.append(cl2)\n",
        "    pipe_models_1.append(cl3)\n",
        "    pipe_models_1.append(cl4)\n",
        "print(\"Number of level 1 models: \", len(pipe_models_1))\n",
        "print(\"Number of subsets: \", len(subsets))\n",
        "print(\"Subsets: \", subsets)\n",
        "# pipe_models_1 = [ \n",
        "#     ('gnb', GaussianNB()),\n",
        "#     #('lg', LogisticRegression(random_state=0)),\n",
        "#     #('nn', KerasClassifier(build_fn=dnn, epochs=2, batch_size=32, verbose=0, callbacks=[logger])),\n",
        "#     #('nn', KerasClassifier(build_fn=dnn, epochs=2, batch_size=32, verbose=0)),\n",
        "#     #('etc', ExtraTreesClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "#     #('rfc', RandomForestClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "#     ('xgb', XGBClassifier(**xgb_params)),           \n",
        "#     ('lgbm', LGBMClassifier(**lgb_params)),\n",
        "#     ('cb', CatBoostClassifier(**catboost_params))\n",
        "# ]\n",
        "subset = list(range(0, len(pipe_models_1), 2))\n",
        "#subset = list(range(0, len(pipe_models_1)))\n",
        "pipe_models_2 = [ \n",
        "    #('gnb', GaussianNB()),\n",
        "    #('nn', KerasClassifier(build_fn=dnn, epochs=2, batch_size=32, verbose=1)),\n",
        "    #('etc', ExtraTreesClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "    #('rfc', RandomForestClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "    ('xgb', make_pipeline(ColumnSelector(cols=tuple(subset)), XGBClassifier(**xgb_params))),           \n",
        "    ('lgbm', make_pipeline(ColumnSelector(cols=tuple(subset)), LGBMClassifier(**lgb_params))),\n",
        "    ('cb', make_pipeline(ColumnSelector(cols=tuple(subset)), CatBoostClassifier(**catboost_params)))\n",
        "]\n",
        "\n",
        "stack1 = StackingTransformer(pipe_models_1,                   # list of models\n",
        "                               #X_train, y_train, X_test,   # data\n",
        "                               regression=False,           # classification task (if you need \n",
        "                                                           #     regression - set to True)\n",
        "                               #mode='oof_pred',            # mode: oof for train set, fit on full \n",
        "                               variant='A',                            #     train and predict test set once\n",
        "                               needs_proba=True,           # predict probabilities (if you need \n",
        "                                                           #     class labels - set to False) \n",
        "                               ##save_dir='.',               # save result and log in current dir \n",
        "                               #save_dir=save_directory,                                 #     (to disable saving - set to None)\n",
        "                               metric=auc,            # metric: callable\n",
        "                               n_folds=5,                  # number of folds\n",
        "                               stratified=True,            # stratified split for folds\n",
        "                               shuffle=True,               # shuffle the data\n",
        "                               random_state=0,             # ensure reproducibility\n",
        "                               verbose=1)                  # print all info\n",
        "\n",
        "stack2 = StackingTransformer(pipe_models_2,                   # list of models\n",
        "                               #X_train, y_train, X_test,   # data\n",
        "                               regression=False,           # classification task (if you need \n",
        "                                                           #     regression - set to True)\n",
        "                               #mode='oof_pred',            # mode: oof for train set, fit on full \n",
        "                               variant='A',                            #     train and predict test set once\n",
        "                               needs_proba=True,           # predict probabilities (if you need \n",
        "                                                           #     class labels - set to False) \n",
        "                               ##save_dir='.',               # save result and log in current dir \n",
        "                               #save_dir=save_directory,                                 #     (to disable saving - set to None)\n",
        "                               metric=auc,            # metric: callable\n",
        "                               n_folds=5,                  # number of folds\n",
        "                               stratified=True,            # stratified split for folds\n",
        "                               shuffle=True,               # shuffle the data\n",
        "                               random_state=0,             # ensure reproducibility\n",
        "                               verbose=1)                  # print all info"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of level 1 models:  4\n",
            "Number of subsets:  1\n",
            "Subsets:  [array([ 16,  31,  95, 154, 125,   5,  53, 123, 114, 146,  96,  14, 118])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JKCHbpdZ-818",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats import rankdata\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class Rank(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Define fit and transform for sklearn pipeline\"\"\"\n",
        "    def __init__(self, method='average'):\n",
        "        self.method = method\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return np.apply_along_axis(rankdata, 0, X)\n",
        "        #return X\n",
        "stack3 = make_pipeline(Rank(), XGBClassifier(**xgb_params))\n",
        "\n",
        "steps = [('stack1', stack1),\n",
        "         ('stack2', stack2),\n",
        "        ('stack3', stack3)]\n",
        "\n",
        "# Init Pipeline\n",
        "pipe = Pipeline(steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMTsKY_TApPR",
        "colab_type": "code",
        "outputId": "f6039360-c592-4f2d-b8ea-5791af3079ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2189
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit\n",
        "pipe = pipe.fit(X_train, y_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [auc]\n",
            "variant:      [A]\n",
            "n_estimators: [4]\n",
            "\n",
            "estimator  0: [gnb0: Pipeline]\n",
            "    MEAN:     [0.53753113] + [0.07793492]\n",
            "\n",
            "estimator  1: [xgb0: Pipeline]\n",
            "    MEAN:     [0.50000000] + [0.00000000]\n",
            "\n",
            "estimator  2: [lgbm0: Pipeline]\n",
            "[1]\tvalid_0's auc: 0.325397\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalid_0's auc: 0.287115\n",
            "[3]\tvalid_0's auc: 0.348273\n",
            "[4]\tvalid_0's auc: 0.343604\n",
            "[5]\tvalid_0's auc: 0.358077\n",
            "[6]\tvalid_0's auc: 0.346405\n",
            "[7]\tvalid_0's auc: 0.356676\n",
            "[8]\tvalid_0's auc: 0.355742\n",
            "[9]\tvalid_0's auc: 0.373016\n",
            "[10]\tvalid_0's auc: 0.442577\n",
            "[11]\tvalid_0's auc: 0.468721\n",
            "[12]\tvalid_0's auc: 0.452848\n",
            "[13]\tvalid_0's auc: 0.439776\n",
            "[14]\tvalid_0's auc: 0.43324\n",
            "[15]\tvalid_0's auc: 0.460317\n",
            "[16]\tvalid_0's auc: 0.439776\n",
            "Early stopping, best iteration is:\n",
            "[11]\tvalid_0's auc: 0.468721\n",
            "[1]\tvalid_0's auc: 0.568627\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalid_0's auc: 0.49113\n",
            "[3]\tvalid_0's auc: 0.53408\n",
            "[4]\tvalid_0's auc: 0.53408\n",
            "[5]\tvalid_0's auc: 0.511671\n",
            "[6]\tvalid_0's auc: 0.504669\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.568627\n",
            "[1]\tvalid_0's auc: 0.475575\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalid_0's auc: 0.461207\n",
            "[3]\tvalid_0's auc: 0.41092\n",
            "[4]\tvalid_0's auc: 0.429598\n",
            "[5]\tvalid_0's auc: 0.425647\n",
            "[6]\tvalid_0's auc: 0.472342\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.475575\n",
            "[1]\tvalid_0's auc: 0.468798\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalid_0's auc: 0.436055\n",
            "[3]\tvalid_0's auc: 0.525424\n",
            "[4]\tvalid_0's auc: 0.498459\n",
            "[5]\tvalid_0's auc: 0.510786\n",
            "[6]\tvalid_0's auc: 0.380971\n",
            "[7]\tvalid_0's auc: 0.378274\n",
            "[8]\tvalid_0's auc: 0.366718\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 0.525424\n",
            "[1]\tvalid_0's auc: 0.513158\n",
            "Training until validation scores don't improve for 5 rounds.\n",
            "[2]\tvalid_0's auc: 0.502153\n",
            "[3]\tvalid_0's auc: 0.491148\n",
            "[4]\tvalid_0's auc: 0.475359\n",
            "[5]\tvalid_0's auc: 0.441388\n",
            "[6]\tvalid_0's auc: 0.450239\n",
            "Early stopping, best iteration is:\n",
            "[1]\tvalid_0's auc: 0.513158\n",
            "    MEAN:     [0.52609195] + [0.02699611]\n",
            "\n",
            "estimator  3: [cb0: Pipeline]\n",
            "    MEAN:     [0.49477251] + [0.08663889]\n",
            "\n",
            "Train set was detected.\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [gnb0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [xgb0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [lgbm0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  3: [cb0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [auc]\n",
            "variant:      [A]\n",
            "n_estimators: [3]\n",
            "\n",
            "estimator  0: [xgb: Pipeline]\n",
            "    MEAN:     [0.50000000] + [0.00000000]\n",
            "\n",
            "estimator  1: [lgbm: Pipeline]\n",
            "    MEAN:     [0.51849617] + [0.03702651]\n",
            "\n",
            "estimator  2: [cb: Pipeline]\n",
            "    MEAN:     [0.48801046] + [0.03294431]\n",
            "\n",
            "Train set was detected.\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [xgb: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [lgbm: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [cb: Pipeline]\n",
            "    DONE\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xq18Jw09HuJ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# roc on validation data"
      ]
    },
    {
      "metadata": {
        "id": "rqb2dNW2GF9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "5922f583-28c6-4946-f357-b6195e926081"
      },
      "cell_type": "code",
      "source": [
        "y_pred = pipe.predict_proba(X_test)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Final prediction score\n",
        "# print('Final prediction score: %.8f' % log_loss(y_test, y_pred))\n",
        "y_pred_final = [elem[1] for elem in y_pred]\n",
        "roc_auc_score(y_test, y_pred_final)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transforming...\n",
            "\n",
            "estimator  0: [gnb0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [xgb0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [lgbm0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  3: [cb0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [xgb: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [lgbm: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [cb: Pipeline]\n",
            "    DONE\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "rXIi1j3XHnzz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# rocauc on training data"
      ]
    },
    {
      "metadata": {
        "id": "vZVO3Dyqah3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "2ca83c80-fd81-4e2e-8e7c-82148f660106"
      },
      "cell_type": "code",
      "source": [
        "y_pred = pipe.predict_proba(train_data_x)\n",
        "y_pred_final = [elem[1] for elem in y_pred]\n",
        "roc_auc_score(train_data_y, y_pred_final)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transforming...\n",
            "\n",
            "estimator  0: [gnb0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [xgb0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [lgbm0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  3: [cb0: Pipeline]\n",
            "    DONE\n",
            "\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [xgb: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [lgbm: Pipeline]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [cb: Pipeline]\n",
            "    DONE\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "MmlMBfQnG4_f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save Pipeline\n",
        "import joblib\n",
        "_ = joblib.dump(pipe, save_directory + 'pipe_with_stack.pkl')\n",
        "# Load Pipeline\n",
        "pipe_loaded = joblib.load(save_directory + 'pipe_with_stack.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfN4T87FDEln",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict on Kaggle Test"
      ]
    },
    {
      "metadata": {
        "id": "J77lgIu7CFuP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kaggle_pred = pipe.predict_proba(test_data_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OSGFqhE8Cbgr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame()\n",
        "output_df[\"ID_code\"] = test_data_df[\"ID_code\"]\n",
        "pred_final = [elem[1] for elem in kaggle_pred]\n",
        "output_df[\"target\"] = pred_final\n",
        "output_df.to_csv(save_directory + \"predictions.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}