{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stacking.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "i4yUkcdkblT-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstroBoy1/santander/blob/master/stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mUKhe-vC-LIw"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "***"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "9a48e8ea-a4e9-4d07-e8fe-51c1a7c74105",
        "id": "3JM3uflR-LIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install vecstack\n",
        "!pip install catboost"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vecstack in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from vecstack) (0.20.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.14.6)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.11.0)\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.6)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.22.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uC48gUBv-LIX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import time\n",
        "import statistics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from vecstack import stacking\n",
        "from vecstack import StackingTransformer\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import re \n",
        "np.random.seed(0) # ensure reproducibility\n",
        "np.set_printoptions(suppress = True)\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import log_loss\n",
        "# Models\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Stacking\n",
        "from vecstack import stacking\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Input, Flatten, Dropout, BatchNormalization, GaussianNoise\n",
        "from keras import callbacks\n",
        "import keras.backend as K\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from mlxtend.feature_selection import ColumnSelector\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8b364225-a0c1-4b66-d0b0-0f5d69465a1d",
        "id": "IETJszVE-LIH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "O0bwvFih-LHi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_fn = '/content/gdrive/My Drive/santander_data/train.csv'\n",
        "valid_fn = '/content/gdrive/My Drive/santander_data/test.csv'\n",
        "pred_fn = '/content/gdrive/My Drive/santander_data/submission12.csv'\n",
        "train_data_df = pd.read_csv(train_fn)\n",
        "test_data_df = pd.read_csv(valid_fn)\n",
        "train_data_x = train_data_df.drop(columns=[\"ID_code\", \"target\"]).values\n",
        "train_data_y = train_data_df[\"target\"].values\n",
        "test_data_x = test_data_df.drop(columns=[\"ID_code\"]).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPypOQs6GY_Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ]
    },
    {
      "metadata": {
        "id": "EXs3lkQhGY_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "a13733ae-e9d5-4d96-8292-22c0fbc62e2e"
      },
      "cell_type": "code",
      "source": [
        "n_classes = 2\n",
        "length = 1000\n",
        "X, y = train_data_x[:length], train_data_y[:length]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "save_directory = '/content/gdrive/My Drive/santander_results/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-619782bf9e38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msave_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/santander_results/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data_x' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uCWZkCB2r79M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LGB, XGB, Catboost params"
      ]
    },
    {
      "metadata": {
        "id": "7J2mCU9Orz0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lgb_params = {\n",
        "    'bagging_freq': 5,\n",
        "    'bagging_fraction': 0.335,\n",
        "    'boost_from_average':'false',\n",
        "    'boost': 'gbdt',\n",
        "    'feature_fraction': 0.041,\n",
        "    'learning_rate': 0.0083,\n",
        "    'max_depth': -1,\n",
        "    'metric':'auc',\n",
        "    'min_data_in_leaf': 80,\n",
        "    'min_sum_hessian_in_leaf': 10.0,\n",
        "    'num_leaves': 13,\n",
        "    'num_threads': 8,\n",
        "    'tree_learner': 'serial',\n",
        "    'objective': 'binary', \n",
        "    'verbosity': -1}\n",
        "\n",
        "xgb_params = {'tree_method': 'hist',\n",
        " 'objective': 'binary:logistic',\n",
        " 'eval_metric': 'auc',\n",
        " 'learning_rate': 0.0936165921314771,\n",
        " 'max_depth': 2,\n",
        " 'colsample_bytree': 0.3561271102144279,\n",
        " 'subsample': 0.8246604621518232,\n",
        " 'min_child_weight': 53,\n",
        " 'gamma': 9.943467991283027,\n",
        " 'silent': 1,\n",
        "}\n",
        "\n",
        "catboost_params = {'subsample':0.36, #rawdata 0.5  ×2 0.45 ×3 0.36\n",
        "                            'loss_function':'Logloss',\n",
        "                           'random_strength':0,\n",
        "                           'max_depth':3,\n",
        "                           'eval_metric':\"AUC\",\n",
        "                           'learning_rate':0.02,\n",
        "                           #'iterations':60000,\n",
        "                           'iterations':100,\n",
        "                           #class_weights=[1,2],\n",
        "                           'bootstrap_type':'Bernoulli',\n",
        "                           #rsm=0.045,\n",
        "                            'l2_leaf_reg':0.3,\n",
        "                           #'task_type':\"GPU\",\n",
        "                           'random_seed':432013,\n",
        "                           'od_type':\"Iter\",\n",
        "                           'border_count':128,\n",
        "                           'logging_level':'Silent'\n",
        "                           #has_time= True \n",
        "                  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i4yUkcdkblT-"
      },
      "cell_type": "markdown",
      "source": [
        "# NN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Xz6CKnuTblSs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def auc(y_true, y_pred):\n",
        "    \"\"\"ROC AUC metric for both binary and multiclass classification.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : 1d numpy array\n",
        "        True class labels\n",
        "    y_pred : 2d numpy array\n",
        "        Predicted probabilities for each class\n",
        "    \"\"\"\n",
        "    ohe = OneHotEncoder(sparse=False)\n",
        "    y_true = ohe.fit_transform(y_true.reshape(-1, 1))\n",
        "    auc_score = roc_auc_score(y_true, y_pred)\n",
        "    return auc_score\n",
        "\n",
        "# LOGGER\n",
        "class Logger(callbacks.Callback):\n",
        "    def __init__(self, out_path='./', patience=10, lr_patience=3, out_fn='', log_fn=''):\n",
        "        self.auc = 0\n",
        "        self.path = out_path\n",
        "        self.fn = out_fn\n",
        "        self.patience = patience\n",
        "        self.lr_patience = lr_patience\n",
        "        self.no_improve = 0\n",
        "        self.no_improve_lr = 0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        cv_pred = self.model.predict(self.validation_data[0], batch_size=1024)\n",
        "        cv_true = self.validation_data[1]\n",
        "        auc_val = roc_auc_score(cv_true, cv_pred)\n",
        "        if self.auc < auc_val:\n",
        "            self.no_improve = 0\n",
        "            self.no_improve_lr = 0\n",
        "            print(\"Epoch %s - best AUC: %s\" % (epoch, round(auc_val, 4)))\n",
        "            self.auc = auc_val\n",
        "            self.model.save(self.path + self.fn, overwrite=True)\n",
        "        else:\n",
        "            self.no_improve += 1\n",
        "            self.no_improve_lr += 1\n",
        "            print(\"Epoch %s - current AUC: %s\" % (epoch, round(auc_val, 4)))\n",
        "            if self.no_improve >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "            if self.no_improve_lr >= self.lr_patience:\n",
        "                lr = float(K.get_value(self.model.optimizer.lr))\n",
        "                K.set_value(self.model.optimizer.lr, 0.75*lr)\n",
        "                print(\"Setting lr to {}\".format(0.75*lr))\n",
        "                self.no_improve_lr = 0\n",
        "\n",
        "        return\n",
        "\n",
        "# MODEL DEF\n",
        "def dnn():\n",
        "#     inp = Input(shape=(200, 1))\n",
        "#     d1 = Dense(16, activation='relu')(inp)\n",
        "#     fl = Flatten()(d1)\n",
        "#     preds = Dense(1, activation='sigmoid')(fl)\n",
        "#     model = Model(inputs=inp, outputs=preds)\n",
        "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "logger = Logger(patience=10, out_path=save_directory, out_fn='cv_{}.h5')\n",
        "#nn_params = {'nb_epoch':32, 'batch_size':256, 'callbacks':[logger], 'verbose':1}\n",
        "nn_params = {'epochs':32, 'batch_size':256, 'verbose':1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "McU0f1Ge8Acc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stacking Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "WMzNY7Bz8Cp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3786
        },
        "outputId": "065d80ab-c231-4e92-b4cc-d1a08c9b6ea5"
      },
      "cell_type": "code",
      "source": [
        "# Specify steps of Pipeline\n",
        "\n",
        "# Same paramaters to models, but different subfeatures by:\n",
        "# 1. Select a random number for the number of features to select\n",
        "# 2. Randomly select that many features\n",
        "num_subsets = 25\n",
        "subsets = []\n",
        "features = list(range(200))\n",
        "number = list(range(1, 201))\n",
        "pipe_models_1 = []\n",
        "for num in range(num_subsets):\n",
        "    num_features = np.random.choice(number, size=1)[0]\n",
        "    subset = np.random.choice(features, size=num_features, replace=False, p=None)\n",
        "    subsets.append(subset)\n",
        "    cl1 = ('gnb' + str(num), make_pipeline(ColumnSelector(cols=tuple(subset)), GaussianNB()))\n",
        "    cl2 = ('xgb' + str(num), make_pipeline(ColumnSelector(cols=tuple(subset)), XGBClassifier(**xgb_params)))\n",
        "    cl3 = ('lgbm' + str(num), make_pipeline(ColumnSelector(cols=tuple(subset)), LGBMClassifier(**lgb_params)))\n",
        "    cl4 = ('cb' + str(num), make_pipeline(ColumnSelector(cols=tuple(subset)), CatBoostClassifier(**catboost_params)))\n",
        "    pipe_models_1.append(cl1)\n",
        "    pipe_models_1.append(cl2)\n",
        "    pipe_models_1.append(cl3)\n",
        "    pipe_models_1.append(cl4)\n",
        "print(\"Number of level 1 models: \", len(pipe_models_1))\n",
        "print(\"Number of subsets: \", len(subsets))\n",
        "print(\"Subsets: \", subsets)\n",
        "# pipe_models_1 = [ \n",
        "#     ('gnb', GaussianNB()),\n",
        "#     #('lg', LogisticRegression(random_state=0)),\n",
        "#     #('nn', KerasClassifier(build_fn=dnn, epochs=2, batch_size=32, verbose=0, callbacks=[logger])),\n",
        "#     #('nn', KerasClassifier(build_fn=dnn, epochs=2, batch_size=32, verbose=0)),\n",
        "#     #('etc', ExtraTreesClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "#     #('rfc', RandomForestClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "#     ('xgb', XGBClassifier(**xgb_params)),           \n",
        "#     ('lgbm', LGBMClassifier(**lgb_params)),\n",
        "#     ('cb', CatBoostClassifier(**catboost_params))\n",
        "# ]\n",
        "pipe_models_2 = [ \n",
        "    #('gnb', GaussianNB()),\n",
        "    #('nn', KerasClassifier(build_fn=dnn, epochs=2, batch_size=32, verbose=1)),\n",
        "    #('etc', ExtraTreesClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "    #('rfc', RandomForestClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "    ('xgb', XGBClassifier(**xgb_params)),           \n",
        "    ('lgbm', LGBMClassifier(**lgb_params)),\n",
        "    ('cb', CatBoostClassifier(**catboost_params))\n",
        "]\n",
        "\n",
        "stack1 = StackingTransformer(pipe_models_1,                   # list of models\n",
        "                               #X_train, y_train, X_test,   # data\n",
        "                               regression=False,           # classification task (if you need \n",
        "                                                           #     regression - set to True)\n",
        "                               #mode='oof_pred',            # mode: oof for train set, fit on full \n",
        "                               variant='A',                            #     train and predict test set once\n",
        "                               needs_proba=True,           # predict probabilities (if you need \n",
        "                                                           #     class labels - set to False) \n",
        "                               ##save_dir='.',               # save result and log in current dir \n",
        "                               #save_dir=save_directory,                                 #     (to disable saving - set to None)\n",
        "                               metric=auc,            # metric: callable\n",
        "                               n_folds=5,                  # number of folds\n",
        "                               stratified=True,            # stratified split for folds\n",
        "                               shuffle=True,               # shuffle the data\n",
        "                               random_state=0,             # ensure reproducibility\n",
        "                               verbose=1)                  # print all info\n",
        "\n",
        "stack2 = StackingTransformer(pipe_models_2,                   # list of models\n",
        "                               #X_train, y_train, X_test,   # data\n",
        "                               regression=False,           # classification task (if you need \n",
        "                                                           #     regression - set to True)\n",
        "                               #mode='oof_pred',            # mode: oof for train set, fit on full \n",
        "                               variant='A',                            #     train and predict test set once\n",
        "                               needs_proba=True,           # predict probabilities (if you need \n",
        "                                                           #     class labels - set to False) \n",
        "                               ##save_dir='.',               # save result and log in current dir \n",
        "                               #save_dir=save_directory,                                 #     (to disable saving - set to None)\n",
        "                               metric=auc,            # metric: callable\n",
        "                               n_folds=5,                  # number of folds\n",
        "                               stratified=True,            # stratified split for folds\n",
        "                               shuffle=True,               # shuffle the data\n",
        "                               random_state=0,             # ensure reproducibility\n",
        "                               verbose=1)                  # print all info"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of level 1 models:  100\n",
            "Number of subsets:  25\n",
            "Subsets:  [array([162, 103,  10,  32, 178, 144, 125,  13, 150, 173,  53, 177, 151,\n",
            "       136, 118,  22,  61, 142,  99,  45, 141, 182, 175,  21, 124, 153,\n",
            "        67,  14,  95, 199,  76, 183,  68,  55, 102,  56,  70, 148,  64,\n",
            "       180, 111, 158, 156,  88, 169, 152,  93, 186,  79,  38,  16, 138,\n",
            "       167,  92,  33, 157, 131,  41, 189, 137,  52,  15, 130, 119, 170,\n",
            "       109,  29,   3,  17,  74, 132, 139,  50,  31,  12,  57, 165,  34,\n",
            "       134, 133, 179,  80,  42, 159, 161,  84, 114,  77, 115, 129,   8,\n",
            "       191,  25, 120,  94,  78,   9,  63, 147, 190,  59,  46,  39, 123,\n",
            "        91,  66,   7,  24,   5,  19,   4, 117, 122,  85, 149, 197, 126,\n",
            "       105, 181,  54,  81,  97,  86,  47,  20, 112,  11, 145,  72,   6,\n",
            "        18,  23, 110, 198, 108, 163, 188, 171, 166,  75,  83,  49,  89,\n",
            "       196,  82, 128,   0, 174,  43,  35, 184,  65, 146, 154,  58,  73,\n",
            "       113, 193, 185,   1,  71, 164,  40, 168, 187, 127,  36]), array([181, 106, 132, 153,  40, 141, 196, 112,  48,  25,  50, 140, 193,\n",
            "        60,  96,  44,  41,  70,  31, 189, 174, 169,  21, 149, 147,  74,\n",
            "       168, 102,  71, 139,  26, 183,  37,  32, 135,  56, 138,  27, 119,\n",
            "       152, 116, 185,   9,  98,  67, 187, 161, 114,  65,  92, 180, 130,\n",
            "        75, 170, 103, 199, 175,  16,  35,  97, 115, 111,   4,  54,  55,\n",
            "       142,  57,  94,   5, 178, 163,  81,  87, 125, 109,  72,  14, 179,\n",
            "        30, 108, 100,  78,  38, 110, 127, 173,  45, 136, 191, 198,  11,\n",
            "         1,  59,  22, 158, 120, 164]), array([172,  91, 182,  85, 132, 146,   2, 128, 121,  36,  50, 114,   8,\n",
            "       153, 143,  46, 149, 175,  44, 145, 193, 144, 158,  63,  18,  96,\n",
            "        83, 111,  81, 166,  20,   4,  51, 187,  62,  76, 122, 113,  61,\n",
            "        72, 106, 164,  75, 120, 186,  15]), array([ 32,  41, 105,  17, 148, 131, 179,  70,  36,  30,  56,   8, 145,\n",
            "        77, 193, 159, 153,  49, 198,  55, 144, 173,  86, 178, 121, 113,\n",
            "       163,  78, 132, 150,  54,  59,  51,  76,  98,  69,  82, 161,  67,\n",
            "       108,   2, 116, 174,  27,  16, 152,  74, 189, 146, 164,  99, 185,\n",
            "         9,   1,  62, 118,  47, 169, 175, 160, 127, 196,  81,  18,  58,\n",
            "         0,  91, 133,  45, 184,   6,  57, 181, 129,  42, 102, 137,  68,\n",
            "        46, 128, 142,  10, 157, 155,  37, 107,  73, 138,  23, 101, 177,\n",
            "       166, 125, 183, 134,  94,  40,  92,  83,   4,  48,  65,  80,  14,\n",
            "       106,  90, 168,  79,  52,  96, 119, 109, 170,  34,   5, 117, 162,\n",
            "       199, 112]), array([ 67, 134, 160,  91,  10, 146, 188, 110, 105,  16, 100, 168, 145,\n",
            "       176, 189, 187,  46, 137, 144, 164,  69,  31, 149, 102,  86,  76,\n",
            "        11,  19, 171,  88, 193,  57,  44, 190,  60, 181,  97, 132,  80,\n",
            "        25, 135, 151, 111, 150,  26, 173, 141, 186,  27,   8, 162, 158,\n",
            "        83,  94,   0,   2, 191,  82,  48,  35,  42, 119, 107,   6,  74,\n",
            "        12,  90, 126, 198, 121,  33, 192, 197,  43,  68, 156,  40,  14,\n",
            "        58, 159,  41,  36, 175, 196,  39, 124, 161,  32,  79, 143, 103,\n",
            "        20, 172, 180,  73,   4,  95,  89,  51,  54, 195,   3,  15,  84,\n",
            "       185,  24,  62, 114,  66, 127, 136, 131,   7, 179,  77,  13,  71,\n",
            "       182, 148,  56, 138, 170,  63,  93,  38,  30, 154, 166, 199, 147,\n",
            "       101,  50,  29,  55,  18, 139, 118, 167, 165,  75, 142, 130,  52,\n",
            "         5, 177, 108, 112, 155, 163,  61,  64,  72,  53,  98, 183,  17,\n",
            "       113, 106, 169,  47, 123,  49, 120,  81, 140,  96,  21,  92,  78,\n",
            "       184, 174, 117, 194, 122, 128,   1,  28, 109,  37,  45, 125, 153,\n",
            "       116,  59,  22, 178,  23,   9]), array([ 93, 177, 170, 106, 146, 149, 188,  14,  70,  63,  82, 166, 119,\n",
            "       164, 132, 180, 175,  53,  81,  26, 167, 190, 105,  65,   3,  22,\n",
            "       153, 102, 159,  19, 111,  84,  38, 138,  89, 118, 108, 195,  97,\n",
            "        31,  69, 150, 127, 103,  37, 171, 178,   7,  21, 117,  35, 116,\n",
            "       113,  20, 194,   0, 100, 139,  61,  36,  92,  41,  40, 125,  90,\n",
            "       165,  42,  45, 107, 179, 121,  66,  76,  80,  12,  74,  44, 187,\n",
            "       162,  25,  27, 104, 114, 191,  32, 136,  11,  57,  85, 174, 120,\n",
            "       198, 156, 168,  64,  24, 134,  56,  39, 112,  49,  59,  96,  17,\n",
            "       145,  91, 130, 142, 183, 131,  54,  79, 154,  83,  33, 199, 169,\n",
            "       152, 192, 184,  28, 172,  72,  46,  62, 182,  75,  47,  71,  78,\n",
            "         2, 193,  73, 122, 197, 158, 129,  30,  18, 137,   6, 148,  15,\n",
            "        87, 163, 101, 155, 128,   4,  86,  94, 160, 147, 126,  48, 186,\n",
            "        60,  34]), array([106, 125, 116, 196, 146, 154, 131,  91, 168, 166,  13, 136,  44,\n",
            "        67,  57, 181, 153,  69,  63, 189,  18,   7, 118, 110,  19,   3,\n",
            "       193,  50, 128,   4, 144,  37,  64,  68,  54, 111, 191, 165,  14,\n",
            "        72, 184,  40, 167,  25, 129,  27,  84, 190, 138,  85, 133,  98,\n",
            "       183,  58, 114, 115, 150,  92,  89,  51,  73,  77,  74,  46, 192,\n",
            "        96, 185, 102, 175, 103,  86,  16,  78, 113,  94, 163, 135,  87,\n",
            "       143,  45, 198,  20, 194, 179,   5,  75,  49,  42,  62, 109,  52,\n",
            "        61,  17, 120,   1, 123,   0,  53, 195,  11,  70,  90, 127]), array([ 85,  15,  23, 182, 153,  62,   1, 100,   7, 161,  74,  84,   0,\n",
            "        30,  94,  54,  87, 191, 155,  73, 111, 139,  13,  31, 130, 157,\n",
            "       137,  34,  27, 149,  35, 142, 146,  39, 106,  64, 189,  83, 175,\n",
            "       151,  68, 141,  78, 127,  37,  20, 102, 150, 112, 110,  97, 183,\n",
            "       180,  65,  48, 115, 144, 148, 119, 138,  19,  90, 108, 166,  24,\n",
            "        96, 140,   4,  95, 186, 156, 117,  77,  49, 114,  55,   3, 136,\n",
            "        82,  33, 176]), array([ 51,  72, 143,  76,  42, 182, 116, 123,  70,  15,  75, 125,  23,\n",
            "        29,  19, 135, 137,  10, 145,  17, 121,  90, 134,  43,  46,  91,\n",
            "         6,   2,  45, 186, 153,   3, 136,  12,  66, 161, 190, 146, 128,\n",
            "       199,  34,  35, 155, 185, 112,  94, 150, 126, 113,  58, 163, 156,\n",
            "        83,  73,  53, 160, 144, 119, 100,  25,  65,  56,  44, 151,  41,\n",
            "        16, 122, 118,  64,  85, 170,  82,  87,  93,   7, 149, 191,  61,\n",
            "       171,  22, 187, 101, 196,  31, 107, 192,  92,  77,  13, 111,  86,\n",
            "        55, 188,  69, 180,  62, 109, 154,   8]), array([ 42,  17,  80, 176, 114, 165, 149, 138,  93, 133,  94,  78, 143,\n",
            "        96, 198,  68, 112, 175, 184,  77,  11, 117, 118, 195,  35,  33,\n",
            "       174,  84, 124, 169,  28,  64, 163, 192,  75,  59, 136, 123,  95,\n",
            "        86, 180, 142, 188, 160,  43,  85, 115,  29,  39,  61, 187, 109,\n",
            "       177,  57, 183, 116, 128, 119,  18,  30,   8, 179, 127,  38,  72,\n",
            "       152, 189,  79]), array([ 10, 100,  62, 149,  13,  95, 180,  52, 141, 174,  41, 117, 129,\n",
            "         8,  14,  85,  81, 199, 114,  87, 115,  78,  74,  24, 162,  99,\n",
            "        31, 110, 121,  18, 130,  12,  66,  20,   5,  91,  35, 179,   0,\n",
            "        29,   7,  79,  93,  51, 140, 143,  90, 120,  76,  67, 175, 187,\n",
            "        94,  61, 105,  26,   4, 153, 171, 166, 151, 109, 170, 136,  48,\n",
            "       132,  42,  63, 189,  56,   3, 194, 190,  73,  39,  58,  55,  88,\n",
            "       139, 119, 127, 163, 102,  21,  27,   1,  16,  98,  70, 138, 185,\n",
            "        68, 148,   9, 154, 159,  17, 111, 144, 112,  57,  54,  28,  69,\n",
            "       135,  77, 146,  34, 173, 142, 158,  38, 134,  84, 164, 160,  82,\n",
            "       123, 126, 128,  19, 182, 176,  32,  96, 106, 125,  44, 157, 191,\n",
            "        47, 184, 147, 188,  23,  49,  43, 186,  36,  15, 116, 177, 124,\n",
            "         2,  37,  25, 196, 195,  53, 192,  46, 198,  50,  64, 169,  86,\n",
            "        33, 103, 178,  45, 183,  65, 113,   6,  60, 131, 137,  72, 156,\n",
            "       108, 168]), array([ 65,  91,  61,  16, 149,  80, 171, 116, 190, 147,  63, 158,  43,\n",
            "       188, 184, 144, 107, 173,  30, 101, 143, 105,  90, 140,  71,  99,\n",
            "       155,   2, 115, 104,  51,  55, 100,  36,  69, 156, 108, 113,  68,\n",
            "        85,  26,   9,  73, 125,  78, 128, 187,  45, 103, 189, 181,  64,\n",
            "        31,  13,  81,  20, 157, 164, 191,   5, 126,  32,  92, 138,  86,\n",
            "         1, 133,  77, 192,  34,  24, 153, 169, 111, 198,  25,   3, 131,\n",
            "       174,  17,  21, 159,  47,  19, 178,  12,  11, 120,  40, 122,  89,\n",
            "        67, 114, 135, 176, 161, 193,   8, 165, 110,   4, 183, 177, 150,\n",
            "        79, 199,  29, 123,  28, 196, 179,  96,  84,  37, 186, 106,  59,\n",
            "       172, 197,  98,  87,   7,  62,  54,  50, 146, 154, 109,  23,  53,\n",
            "       145, 118,  49,  48,  38, 130]), array([186, 120, 184, 197, 176, 108, 156,  51, 128,  74,  81, 142, 129,\n",
            "       106,  96,  44,  99,  29,  38,  68, 121, 192,  97, 175,  57, 105,\n",
            "        36, 191, 130]), array([ 51,  46, 161, 138, 180, 114, 186,  16, 150,  21,  98,  27, 149,\n",
            "        17,  60, 120, 101, 134,  50, 176,  80, 130,  39,   9,  90, 193,\n",
            "       181,  47, 112,   7, 153, 179,  88,  53,  89, 199,  54, 163,  85,\n",
            "        72, 145, 182, 165, 136, 191, 105, 184, 109, 147,  57, 158, 129,\n",
            "        82, 167, 183, 137, 169, 188, 144, 116,  19, 133,  52,  43, 168,\n",
            "        95, 151,  29,  24,  93,   3, 197, 171,  48,  71,  65,  23,  25,\n",
            "         1,  61, 139,  74,  28,  62]), array([110,  62,  50,  71,  30,  85, 101, 185, 192, 162,  67,  93,  42,\n",
            "        60,  84,  95,   8, 127,   1,  20, 151, 170, 165, 164, 169, 182,\n",
            "       188,  64,  34, 158, 116, 124,  75, 197,   7,  24,  51,  81, 191,\n",
            "       149, 100, 112, 152, 172, 190,  87,  44, 129, 155,   9, 128,  91,\n",
            "       104, 130, 115, 145,  32,  41,  99,  54,  88, 173, 140,  78,  65,\n",
            "        61,  18, 160,  80, 142,  23,  14, 175,  49, 131,   6, 199, 108,\n",
            "       189,  63, 147, 154,  13, 148, 180,  19, 168, 195, 107,  98, 178,\n",
            "       117, 118,   2,  66,  56,  43,  72, 187,   0, 119, 153,   5,  90,\n",
            "        10, 194, 177,  94, 186,  58, 163,  33, 198,  89, 125, 156]), array([ 54, 141,  17,  97, 187, 130,  98,  36,   9,  93,   6,  55, 113,\n",
            "         2,  25,  66, 111, 170,  24, 100, 174,  72,  57, 119,  58, 166,\n",
            "        23, 110, 195, 199,  75, 144, 114,  86, 136,  81,  39,  21, 151,\n",
            "       106,  50,   4,   0, 185,  89,  78, 132,  53,  92,  49, 159,  61,\n",
            "       196, 165, 173,  65,  69, 122, 180, 155, 135, 109,  83, 171, 169,\n",
            "       120,  70, 107,  34, 138,  46,  45, 179, 105]), array([ 73,  70,  17,  33,   1, 193,  49,  18,  79, 195,  99,  59, 163,\n",
            "       142,  97,  83, 145, 153, 160, 105,  90, 101, 161, 196, 182,   7,\n",
            "        82,  53, 132, 107, 199, 170, 147,  80,  95, 164,  78,  44, 128,\n",
            "        30, 114,  63,  67, 173,  41, 151, 122, 177, 129, 178,  68,  23,\n",
            "       126, 189,  34, 159,  43,  26, 188, 158,  57, 155,  86, 192,  28,\n",
            "        89, 181, 136, 150, 152, 119, 102, 139, 125, 141,  16,  88, 140,\n",
            "        27,  69, 169,  13, 106,  48,   3, 131, 198, 190, 179,  76,  52,\n",
            "       194,   6, 174,  38, 185, 137, 135,  92, 100,  46, 144,  51, 112,\n",
            "         2,  64, 186,   5,   8, 184, 127,  47, 121, 104, 143,  66, 109,\n",
            "        42,  71, 118, 116,  35, 172,  37, 110,  94,  22,  85, 162,  74,\n",
            "       123, 157, 115,  81,  65, 165, 191, 197,  98, 175,  87,  45, 103,\n",
            "        20,  61, 180,   9,  11, 117, 176,  12,  54, 133,  62,  77, 171,\n",
            "        60,   0, 154,  19,  10, 120,  55,  91,  39, 138, 183, 148, 166,\n",
            "         4,  15, 124,  58,  31,  75,  84,  40, 111, 187, 168, 134, 167,\n",
            "        72,  21,  32, 113,  36]), array([120, 100,  27, 182, 106,  76,  26, 186, 129, 165,  78,  97, 193,\n",
            "       180,   1,  64,  75, 177, 155,   4,   2, 157,  48, 192,  34,  16,\n",
            "        15,  90,  98,  54, 104, 159,  11,  14,  19,  79,  92, 171,   6,\n",
            "       173, 147,  12, 191,  17,  87,  35, 161,  53,  93,  25, 166,  51,\n",
            "       154, 151,  20, 188, 134, 108,  31, 181]), array([ 12,  63, 173,  52,  34, 181, 101, 129, 117,   2,   6,  49,  84,\n",
            "        10,  86, 109, 184,   4,  85,  80,  89,  64, 167,  57,  75, 180,\n",
            "       152,  68,  90, 193, 157, 130, 185, 160,  74, 159, 122, 112, 113,\n",
            "       138, 170, 126,  32, 131,  15,  29, 148, 137,  19,  88,   7,  30,\n",
            "       120,  69, 194,  66,  56, 114,  13,   1,  18, 166,  33, 116, 163,\n",
            "       198, 121, 107, 123,  46, 105, 103,  71,  87, 150, 162,  17,  22,\n",
            "        70, 183,  36, 139,  91, 177,  82,   5,   9,  38, 175, 176,  21,\n",
            "        48, 119, 142,  37,  76, 172, 174,  92,  27, 141,  81, 118,  44,\n",
            "       195, 153,   3, 106, 149,  25, 104,  95,  35,   0,  83, 171, 161,\n",
            "       192,  40,  42,  14,  11,  28,  73, 111,   8,  94,  16, 133, 164,\n",
            "       191, 100, 155]), array([ 55,  92,  19,  13,   9, 111,  47,  78,   7,  67, 165, 130, 139,\n",
            "        86, 118,  89,  93,  73, 125, 133, 153, 143, 190, 189, 137, 192,\n",
            "        66, 123, 112,  33,  39,  95,  84,  76,  63, 182, 188, 181,  64,\n",
            "        44,   0, 138,   1,  36, 144,  30,  90, 193, 184,  51,  91, 159,\n",
            "        60,  28,  74,  46,  52,  31, 151, 195, 136,  34,  49,  80, 191,\n",
            "        12, 117,  21,  23,  29, 187, 156,  50, 126, 170,  62,  65,  10]), array([143,  49, 153, 116,  36, 169, 183, 115, 113, 150, 110, 191, 117,\n",
            "       197,  42,  71, 126, 174,  22,  41,  70, 184,  50, 119, 180, 185,\n",
            "       163,  64, 101, 187, 134,  83,  23, 168,  34,  89, 190, 192, 133,\n",
            "       145, 142, 137,  67, 167, 127, 139, 171, 179, 182, 103,  95, 136,\n",
            "        20,  97,  60, 105, 178,  28, 114, 151,  52, 160, 125,  61,  93,\n",
            "         3,  68, 135, 148,  51, 124,   0, 128,  90,  32,   5,  24, 156,\n",
            "       189,  29, 165, 132,  82, 158, 186,  86,  21, 102,  45,  94,   9,\n",
            "         4,  14, 130,  13,  96, 181,  81,  84, 149,  30,  80,  58,  72,\n",
            "       193, 194, 120, 106, 196, 173,  92,  85,  55,  75,  39,  37,  99,\n",
            "        44,  78,  12, 154,   7,  19,  38, 146,  48, 157,  62,  26,  43,\n",
            "       170, 172,  76,  15,  35, 159, 164,  77, 138,  53,   8,  66, 155,\n",
            "       131,  16, 177,  79,  25, 108,  27, 121, 188,   2,  74, 129, 112,\n",
            "        88, 195, 198, 162, 104, 100, 176,  57, 144, 147,  33,  18, 166,\n",
            "        87, 109,  65,   1,  63,  54, 118, 161,  11,   6,  10,  47,  17,\n",
            "       111,  69, 122,  59,  31,  40, 199,  56,  73]), array([138, 168, 140,   7,  84,  67,  74,  81, 165, 183,  97,  42,  88,\n",
            "       108,  96, 129, 191,   8,   4,  19, 195, 178,  37, 118,   2,  20,\n",
            "        13, 130,  75,  95,  71, 116,  79, 146,  41, 189,  65,  48]), array([136,  50,  53, 135, 115,  96, 118,  64,  85, 161,  55, 191, 124,\n",
            "       114,  99, 156, 149, 146, 155,  37, 104,  40,  41, 158,  78,   2,\n",
            "       131, 140,  24, 126, 188,  59,  34, 189,  97, 122,  90,   1,  94,\n",
            "       112,  77, 198, 162, 109,  42,  82,  17, 154,   8,  66,  47,  33,\n",
            "        22, 105, 123,  71,  20,  23,  49,  92, 179,  16, 119, 197, 181,\n",
            "       116, 199, 193,  18,   5, 129, 178,  62, 174, 101,  14,  76,  35,\n",
            "       107, 125, 111,   3,  46, 187, 177,  28,  26, 133,  38, 121, 195,\n",
            "        15,   6,  44, 166, 143, 194,  63,  19,   9,  88,  60,  91, 168,\n",
            "        81, 132,  21]), array([ 82,  67, 151, 112,  83,  10, 140, 130, 120,  26,  76, 197, 123,\n",
            "        35, 198,  98, 181,  39,  62,  29, 171,  75, 183,   7,  36, 173,\n",
            "         3,  60,  17,  63,   6, 174,  72,  74, 111, 188,  51,   0, 125,\n",
            "        54,   8, 187,  91,  58,  84, 110,  33, 176, 184,  15, 131,  42,\n",
            "       147, 185,  93, 104,   2, 194, 154, 105,  95,  96, 121,  20,  69,\n",
            "       129, 193, 180, 103, 161, 136, 118, 132, 182, 172, 196, 122, 139,\n",
            "        48, 124, 189,  66, 166, 106, 141, 133, 168,  47, 149, 177,  56,\n",
            "        71,  94,  92,   1, 162,  45,  25,  79,  12, 150,  14, 169,  30,\n",
            "       192,  32,  64, 146,  97, 158, 102,  85,  81,  88, 101, 117,  55,\n",
            "       191, 179, 157,  53,  46, 160,  86, 116, 143,  27, 113, 137,  70,\n",
            "        13,  16,  52,  28,  68, 178, 148,  22, 107,  40, 186,  34, 152,\n",
            "        59, 167, 119, 170, 190, 175, 114,  57, 108, 142,  89, 156,  37,\n",
            "        77,  19,  31,  50,   9,  65, 155]), array([  3, 115,  20,  70, 199, 129, 176, 151,  99,  76, 173,  89, 119,\n",
            "        94,  53, 190, 122, 188,  79, 141, 140,  93, 131,  27,  40,  25,\n",
            "       134,  29,  45,  42,  19, 189,   8,  17, 139,  85, 117, 175,  75,\n",
            "       196, 155, 172, 109,   5,  22,  26, 136, 113, 174, 154, 111,  12,\n",
            "       107, 125, 186, 197, 185,  23,  41, 195,  43, 133, 148,  16, 183,\n",
            "       160, 135])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JKCHbpdZ-818",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats import rankdata\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class Rank(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Define fit and transform for sklearn pipeline\"\"\"\n",
        "    def __init__(self, method='average'):\n",
        "        self.method = method\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return np.apply_along_axis(rankdata, 0, X)\n",
        "        #return X\n",
        "stack3 = make_pipeline(Rank(), XGBClassifier(**xgb_params))\n",
        "\n",
        "steps = [('stack1', stack1),\n",
        "         ('stack2', stack2),\n",
        "        ('stack3', stack3)]\n",
        "\n",
        "# Init Pipeline\n",
        "pipe = Pipeline(steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMTsKY_TApPR",
        "colab_type": "code",
        "outputId": "c9178715-88bd-446a-daef-125651c551ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1317
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit\n",
        "pipe = pipe.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [auc]\n",
            "variant:      [A]\n",
            "n_estimators: [100]\n",
            "\n",
            "estimator  0: [gnb0: Pipeline]\n",
            "    MEAN:     [0.87314281] + [0.00162505]\n",
            "\n",
            "estimator  1: [xgb0: Pipeline]\n",
            "    MEAN:     [0.80426641] + [0.00395192]\n",
            "\n",
            "estimator  2: [lgbm0: Pipeline]\n",
            "    MEAN:     [0.83169248] + [0.00197881]\n",
            "\n",
            "estimator  3: [cb0: Pipeline]\n",
            "    MEAN:     [0.75573325] + [0.00531221]\n",
            "\n",
            "estimator  4: [gnb1: Pipeline]\n",
            "    MEAN:     [0.80253550] + [0.00256946]\n",
            "\n",
            "estimator  5: [xgb1: Pipeline]\n",
            "    MEAN:     [0.76268084] + [0.00317852]\n",
            "\n",
            "estimator  6: [lgbm1: Pipeline]\n",
            "    MEAN:     [0.77395359] + [0.00156072]\n",
            "\n",
            "estimator  7: [cb1: Pipeline]\n",
            "    MEAN:     [0.72528353] + [0.00397359]\n",
            "\n",
            "estimator  8: [gnb2: Pipeline]\n",
            "    MEAN:     [0.71856962] + [0.00269414]\n",
            "\n",
            "estimator  9: [xgb2: Pipeline]\n",
            "    MEAN:     [0.70351112] + [0.00277283]\n",
            "\n",
            "estimator 10: [lgbm2: Pipeline]\n",
            "    MEAN:     [0.69348201] + [0.00247180]\n",
            "\n",
            "estimator 11: [cb2: Pipeline]\n",
            "    MEAN:     [0.68022057] + [0.00321331]\n",
            "\n",
            "estimator 12: [gnb3: Pipeline]\n",
            "    MEAN:     [0.82502668] + [0.00386256]\n",
            "\n",
            "estimator 13: [xgb3: Pipeline]\n",
            "    MEAN:     [0.77372495] + [0.00324889]\n",
            "\n",
            "estimator 14: [lgbm3: Pipeline]\n",
            "    MEAN:     [0.79183742] + [0.00303519]\n",
            "\n",
            "estimator 15: [cb3: Pipeline]\n",
            "    MEAN:     [0.73628468] + [0.00468353]\n",
            "\n",
            "estimator 16: [gnb4: Pipeline]\n",
            "    MEAN:     [0.88047972] + [0.00165594]\n",
            "\n",
            "estimator 17: [xgb4: Pipeline]\n",
            "    MEAN:     [0.80639924] + [0.00150896]\n",
            "\n",
            "estimator 18: [lgbm4: Pipeline]\n",
            "    MEAN:     [0.83589083] + [0.00146107]\n",
            "\n",
            "estimator 19: [cb4: Pipeline]\n",
            "    MEAN:     [0.75648063] + [0.00425252]\n",
            "\n",
            "estimator 20: [gnb5: Pipeline]\n",
            "    MEAN:     [0.86447114] + [0.00244878]\n",
            "\n",
            "estimator 21: [xgb5: Pipeline]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rqb2dNW2GF9D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = pipe.predict_proba(X_test)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Final prediction score\n",
        "# print('Final prediction score: %.8f' % log_loss(y_test, y_pred))\n",
        "y_pred_final = [elem[1] for elem in y_pred]\n",
        "roc_auc_score(y_test, y_pred_final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vZVO3Dyqah3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = pipe.predict_proba(train_data_x)\n",
        "y_pred_final = [elem[1] for elem in y_pred]\n",
        "roc_auc_score(train_data_y, y_pred_final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MmlMBfQnG4_f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save Pipeline\n",
        "import joblib\n",
        "_ = joblib.dump(pipe, save_directory + 'pipe_with_stack.pkl')\n",
        "# Load Pipeline\n",
        "pipe_loaded = joblib.load(save_directory + 'pipe_with_stack.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfN4T87FDEln",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict on Kaggle Test"
      ]
    },
    {
      "metadata": {
        "id": "J77lgIu7CFuP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kaggle_pred = pipe.predict_proba(test_data_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OSGFqhE8Cbgr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame()\n",
        "output_df[\"ID_code\"] = test_data_df[\"ID_code\"]\n",
        "pred_final = [elem[1] for elem in kaggle_pred]\n",
        "output_df[\"target\"] = pred_final\n",
        "output_df.to_csv(save_directory + \"predictions.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}