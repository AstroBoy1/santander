{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stacking.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "mUKhe-vC-LIw",
        "445ZsYCCGY-3",
        "QPypOQs6GY_Q",
        "OEp4sO4pqGPC",
        "ko7UpPFwGY_f",
        "onNywV8MGY_o",
        "oIFHkOA5GY_1",
        "XLFcWPbUGZAe",
        "a8yNlwH1GZBL",
        "noWn7uBNGZBh",
        "Oiw32ImTGZB_",
        "72UtXfCTGZCG",
        "fpp3rRIjGZCb",
        "cKfBoGm8R4q-",
        "-lPVuCOj-sQn"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstroBoy1/santander/blob/master/stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mUKhe-vC-LIw"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "***"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "1c54bc39-a4a4-448c-8727-36dd0d1c8f8c",
        "id": "3JM3uflR-LIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1132
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 uninstall xgboost\n",
        "!pip3 install xgboost\n",
        "!pip uninstall sklearn\n",
        "!pip install sklearn\n",
        "!pip install scikit-optimize\n",
        "!pip install vecstack\n",
        "!pip install catboost"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling xgboost-0.7.post4:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/xgboost-0.7.post4-py3.6.egg-info\n",
            "    /usr/local/lib/python3.6/dist-packages/xgboost/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled xgboost-0.7.post4\n",
            "Collecting xgboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/49/7e10686647f741bd9c8918b0decdb94135b542fe372ca1100739b8529503/xgboost-0.82-py2.py3-none-manylinux1_x86_64.whl (114.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 114.0MB 336kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.14.6)\n",
            "Installing collected packages: xgboost\n",
            "Successfully installed xgboost-0.82\n",
            "Uninstalling sklearn-0.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/sklearn-0.0-py3.6.egg-info\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled sklearn-0.0\n",
            "Collecting sklearn\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n",
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/44/60f82c97d1caa98752c7da2c1681cab5c7a390a0fdd3a55fac672b321cac/scikit_optimize-0.5.2-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.14.6)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.20.3)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Installing collected packages: scikit-optimize\n",
            "Successfully installed scikit-optimize-0.5.2\n",
            "Collecting vecstack\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/1d/7665736f10f3e15af9d51b4e73c16c8ea798e339f6bf4eadfa1dee77c672/vecstack-0.3.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from vecstack) (0.20.3)\n",
            "Building wheels for collected packages: vecstack\n",
            "  Building wheel for vecstack (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/35/6d/ca/bce17942bcf7c267b13c97c9c95e2f0ecf0b42160e6074f448\n",
            "Successfully built vecstack\n",
            "Installing collected packages: vecstack\n",
            "Successfully installed vecstack-0.3.0\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/62/b442e8d747e8a34ac8a981f7a4ff717c1f887aedb42c3f670660bda41af5/catboost-0.13.1-cp36-none-manylinux1_x86_64.whl (60.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 60.1MB 687kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.11.0)\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.6)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.22.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2.5.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uC48gUBv-LIX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "875a87dd-1d09-464c-9e20-ce3960ebab5f"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import time\n",
        "import statistics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from vecstack import stacking\n",
        "from vecstack import StackingTransformer\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import re \n",
        "np.random.seed(0) # ensure reproducibility\n",
        "np.set_printoptions(suppress = True)\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import log_loss\n",
        "# Models\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Stacking\n",
        "from vecstack import stacking\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Input, Flatten, Dropout, BatchNormalization, GaussianNoise\n",
        "from keras import callbacks\n",
        "import keras.backend as K\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "#from skopt import BayesSearchCV"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "a7238d54-0e3e-4f5b-e2a8-08dd9dfee0a7",
        "id": "IETJszVE-LIH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "O0bwvFih-LHi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_fn = '/content/gdrive/My Drive/santander_data/train.csv'\n",
        "valid_fn = '/content/gdrive/My Drive/santander_data/test.csv'\n",
        "pred_fn = '/content/gdrive/My Drive/santander_data/submission12.csv'\n",
        "train_data_df = pd.read_csv(train_fn)\n",
        "test_data_df = pd.read_csv(valid_fn)\n",
        "train_data_x = train_data_df.drop(columns=[\"ID_code\", \"target\"]).values\n",
        "train_data_y = train_data_df[\"target\"].values\n",
        "test_data_x = test_data_df.drop(columns=[\"ID_code\"]).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3MGNNaR9Mktj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "445ZsYCCGY-3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# AUC metric"
      ]
    },
    {
      "metadata": {
        "id": "FJXuq_R_GyYk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def auc(y_true, y_pred):\n",
        "    \"\"\"ROC AUC metric for both binary and multiclass classification.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : 1d numpy array\n",
        "        True class labels\n",
        "    y_pred : 2d numpy array\n",
        "        Predicted probabilities for each class\n",
        "    \"\"\"\n",
        "    ohe = OneHotEncoder(sparse=False)\n",
        "    y_true = ohe.fit_transform(y_true.reshape(-1, 1))\n",
        "    auc_score = roc_auc_score(y_true, y_pred)\n",
        "    return auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QPypOQs6GY_Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ]
    },
    {
      "metadata": {
        "id": "EXs3lkQhGY_U",
        "colab_type": "code",
        "outputId": "42bba293-ff9c-413d-f818-4be95a191065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# n_classes = 3\n",
        "n_classes = 2\n",
        "# Create data: 500 example, 5 feature, 3 classes\n",
        "# X, y = make_classification(n_samples=500, n_features=5, \n",
        "#                            n_informative=3, n_redundant=1, \n",
        "#                            n_classes=n_classes, flip_y=0, \n",
        "#                            random_state=0)\n",
        "length = 1000\n",
        "X, y = train_data_x[:length], train_data_y[:length]\n",
        "\n",
        "# Make train/test split\n",
        "# As usual in machine learning task we have X_train, y_train, and X_test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "print('Train shape:', X_train.shape)\n",
        "print('Test shape: ', X_test.shape)\n",
        "\n",
        "save_directory = '/content/gdrive/My Drive/santander_results/'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape: (160000, 200)\n",
            "Test shape:  (40000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uCWZkCB2r79M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LGB, XGB, Catboost params"
      ]
    },
    {
      "metadata": {
        "id": "7J2mCU9Orz0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lgb_params = {\n",
        "    'bagging_freq': 5,\n",
        "    'bagging_fraction': 0.335,\n",
        "    'boost_from_average':'false',\n",
        "    'boost': 'gbdt',\n",
        "    'feature_fraction': 0.041,\n",
        "    'learning_rate': 0.0083,\n",
        "    'max_depth': -1,\n",
        "    'metric':'auc',\n",
        "    'min_data_in_leaf': 80,\n",
        "    'min_sum_hessian_in_leaf': 10.0,\n",
        "    'num_leaves': 13,\n",
        "    'num_threads': 8,\n",
        "    'tree_learner': 'serial',\n",
        "    'objective': 'binary', \n",
        "    'verbosity': -1}\n",
        "\n",
        "xgb_params = {'tree_method': 'hist',\n",
        " 'objective': 'binary:logistic',\n",
        " 'eval_metric': 'auc',\n",
        " 'learning_rate': 0.0936165921314771,\n",
        " 'max_depth': 2,\n",
        " 'colsample_bytree': 0.3561271102144279,\n",
        " 'subsample': 0.8246604621518232,\n",
        " 'min_child_weight': 53,\n",
        " 'gamma': 9.943467991283027,\n",
        " 'silent': 1,\n",
        "}\n",
        "\n",
        "catboost_params = {'subsample':0.36, #rawdata 0.5  ×2 0.45 ×3 0.36\n",
        "                            #'custom_loss':'Logloss',\n",
        "                            'loss_function':'Logloss',\n",
        "                           'random_strength':0,\n",
        "                           'max_depth':3,\n",
        "                           'eval_metric':\"AUC\",\n",
        "                           'learning_rate':0.02,\n",
        "                           #'iterations':60000,\n",
        "                           'iterations':100,\n",
        "                           #class_weights=[1,2],\n",
        "                           'bootstrap_type':'Bernoulli',\n",
        "                           #rsm=0.045,\n",
        "                            'l2_leaf_reg':0.3,\n",
        "                           #'task_type':\"GPU\",\n",
        "                           'random_seed':432013,\n",
        "                           'od_type':\"Iter\",\n",
        "                           'border_count':128,\n",
        "                           'logging_level':'Silent'\n",
        "                           #has_time= True \n",
        "                  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OEp4sO4pqGPC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NN"
      ]
    },
    {
      "metadata": {
        "id": "754EyMecqRGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LOGGER\n",
        "class Logger(callbacks.Callback):\n",
        "    def __init__(self, out_path='./', patience=10, lr_patience=3, out_fn='', log_fn=''):\n",
        "        self.auc = 0\n",
        "        self.path = out_path\n",
        "        self.fn = out_fn\n",
        "        self.patience = patience\n",
        "        self.lr_patience = lr_patience\n",
        "        self.no_improve = 0\n",
        "        self.no_improve_lr = 0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        cv_pred = self.model.predict(self.validation_data[0], batch_size=1024)\n",
        "        cv_true = self.validation_data[1]\n",
        "        auc_val = roc_auc_score(cv_true, cv_pred)\n",
        "        if self.auc < auc_val:\n",
        "            self.no_improve = 0\n",
        "            self.no_improve_lr = 0\n",
        "            print(\"Epoch %s - best AUC: %s\" % (epoch, round(auc_val, 4)))\n",
        "            self.auc = auc_val\n",
        "            self.model.save(self.path + self.fn, overwrite=True)\n",
        "        else:\n",
        "            self.no_improve += 1\n",
        "            self.no_improve_lr += 1\n",
        "            print(\"Epoch %s - current AUC: %s\" % (epoch, round(auc_val, 4)))\n",
        "            if self.no_improve >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "            if self.no_improve_lr >= self.lr_patience:\n",
        "                lr = float(K.get_value(self.model.optimizer.lr))\n",
        "                K.set_value(self.model.optimizer.lr, 0.75*lr)\n",
        "                print(\"Setting lr to {}\".format(0.75*lr))\n",
        "                self.no_improve_lr = 0\n",
        "\n",
        "        return\n",
        "\n",
        "# MODEL DEF\n",
        "def dnn():\n",
        "#     inp = Input(shape=(200, 1))\n",
        "#     d1 = Dense(16, activation='relu')(inp)\n",
        "#     fl = Flatten()(d1)\n",
        "#     preds = Dense(1, activation='sigmoid')(fl)\n",
        "#     model = Model(inputs=inp, outputs=preds)\n",
        "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "logger = Logger(patience=10, out_path=save_directory, out_fn='cv_{}.h5')\n",
        "#nn_params = {'nb_epoch':32, 'batch_size':256, 'callbacks':[logger], 'verbose':1}\n",
        "nn_params = {'epochs':32, 'batch_size':256, 'verbose':1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ko7UpPFwGY_f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initialize 1st level models"
      ]
    },
    {
      "metadata": {
        "id": "yAaA1t3IGY_j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_keras_model_1():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, \n",
        "                    input_dim=X_train.shape[1], \n",
        "                    kernel_initializer='normal', \n",
        "                    activation='relu'))\n",
        "    model.add(Dense(n_classes, \n",
        "                    kernel_initializer='normal', \n",
        "                    activation='softmax'))\n",
        "    model.compile(optimizer='rmsprop', \n",
        "                  loss='categorical_crossentropy', \n",
        "                  metrics=['categorical_accuracy'])\n",
        "    return model\n",
        "# Caution! All models and parameter values are just \n",
        "# demonstrational and shouldn't be considered as recommended.\n",
        "models_1 = [ \n",
        "    GaussianNB(),\n",
        "    \n",
        "    #LogisticRegression(random_state=0),\n",
        "    \n",
        "    ExtraTreesClassifier(random_state=0, n_jobs=-1, \n",
        "                         n_estimators=100, max_depth=3),\n",
        "                         \n",
        "    RandomForestClassifier(random_state=0, n_jobs=-1, \n",
        "                           n_estimators=100, max_depth=3),\n",
        "        \n",
        "    #XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "    #              n_estimators=100, max_depth=3, categories='auto'),\n",
        "    XGBClassifier(**xgb_params),           \n",
        "    #LGBMClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "    #               n_estimators=100, max_depth=3)#,\n",
        "    LGBMClassifier(**lgb_params),\n",
        "    CatBoostClassifier(**catboost_params),\n",
        "    #model.fit(X_train, y_train_, validation_data=(X_valid, y_valid))\n",
        "    #Pipeline([('sc', StandardScaler()), ('clf', KerasClassifier(build_fn=dnn, **nn_params))])\n",
        "    #Pipeline([('sc', StandardScaler()), ('clf', Ridge(**ridge_params))])\n",
        "    #KerasClassifier(build_fn=build_keras_model_1, epochs=2, \n",
        "    #                batch_size=32, verbose=0)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "onNywV8MGY_o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Perform stacking"
      ]
    },
    {
      "metadata": {
        "id": "pfceZw1BGY_q",
        "colab_type": "code",
        "outputId": "a862d154-c127-47ce-bdc8-502f63d5f1a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13034
        }
      },
      "cell_type": "code",
      "source": [
        "S_train_1, S_test_1 = stacking(models_1,                   # list of models\n",
        "                               X_train, y_train, X_test,   # data\n",
        "                               regression=False,           # classification task (if you need \n",
        "                                                           #     regression - set to True)\n",
        "                               mode='oof_pred',            # mode: oof for train set, fit on full \n",
        "                                                           #     train and predict test set once\n",
        "                               needs_proba=True,           # predict probabilities (if you need \n",
        "                                                           #     class labels - set to False) \n",
        "                               ##save_dir='.',               # save result and log in current dir \n",
        "                               save_dir=save_directory,                                 #     (to disable saving - set to None)\n",
        "                               metric=auc,            # metric: callable\n",
        "                               n_folds=5,                  # number of folds\n",
        "                               stratified=True,            # stratified split for folds\n",
        "                               shuffle=True,               # shuffle the data\n",
        "                               random_state=0,             # ensure reproducibility\n",
        "                               verbose=1)                  # print all info\n",
        "# S_train_1, S_test_1 = stacking(models_1,                   # list of models\n",
        "#                                X_train, y_train, X_test,   # data\n",
        "#                                regression=False,           # classification task (if you need \n",
        "#                                                            #     regression - set to True)\n",
        "#                                mode='oof_pred',            # mode: oof for train set, fit on full \n",
        "#                                                            #     train and predict test set once\n",
        "#                                needs_proba=True,           # predict probabilities (if you need \n",
        "#                                                            #     class labels - set to False) \n",
        "#                                ##save_dir='.',               # save result and log in current dir \n",
        "#                                save_dir=save_directory,                                 #     (to disable saving - set to None)\n",
        "#                                metric=auc,            # metric: callable\n",
        "#                                n_folds=5,                  # number of folds\n",
        "#                                stratified=True,            # stratified split for folds\n",
        "#                                shuffle=True,               # shuffle the data\n",
        "#                                random_state=0,             # ensure reproducibility\n",
        "#                                verbose=1)                  # print all info"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [auc]\n",
            "mode:         [oof_pred]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [XGBClassifier]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    ----\n",
            "    MEAN:     [0.77202972] + [0.02372778]\n",
            "    FULL:     [0.77166960]\n",
            "\n",
            "    Fitting on full train set...\n",
            "\n",
            "model  1:     [LGBMClassifier]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    ----\n",
            "    MEAN:     [0.78647202] + [0.01994472]\n",
            "    FULL:     [0.78433913]\n",
            "\n",
            "    Fitting on full train set...\n",
            "\n",
            "model  2:     [CatBoostClassifier]\n",
            "0:\ttotal: 93.4ms\tremaining: 9.25s\n",
            "1:\ttotal: 135ms\tremaining: 6.63s\n",
            "2:\ttotal: 172ms\tremaining: 5.58s\n",
            "3:\ttotal: 210ms\tremaining: 5.04s\n",
            "4:\ttotal: 247ms\tremaining: 4.7s\n",
            "5:\ttotal: 289ms\tremaining: 4.52s\n",
            "6:\ttotal: 333ms\tremaining: 4.43s\n",
            "7:\ttotal: 376ms\tremaining: 4.32s\n",
            "8:\ttotal: 416ms\tremaining: 4.21s\n",
            "9:\ttotal: 467ms\tremaining: 4.2s\n",
            "10:\ttotal: 504ms\tremaining: 4.08s\n",
            "11:\ttotal: 553ms\tremaining: 4.05s\n",
            "12:\ttotal: 594ms\tremaining: 3.98s\n",
            "13:\ttotal: 634ms\tremaining: 3.89s\n",
            "14:\ttotal: 676ms\tremaining: 3.83s\n",
            "15:\ttotal: 718ms\tremaining: 3.77s\n",
            "16:\ttotal: 756ms\tremaining: 3.69s\n",
            "17:\ttotal: 795ms\tremaining: 3.62s\n",
            "18:\ttotal: 831ms\tremaining: 3.54s\n",
            "19:\ttotal: 872ms\tremaining: 3.49s\n",
            "20:\ttotal: 908ms\tremaining: 3.42s\n",
            "21:\ttotal: 948ms\tremaining: 3.36s\n",
            "22:\ttotal: 990ms\tremaining: 3.31s\n",
            "23:\ttotal: 1.03s\tremaining: 3.26s\n",
            "24:\ttotal: 1.07s\tremaining: 3.2s\n",
            "25:\ttotal: 1.11s\tremaining: 3.15s\n",
            "26:\ttotal: 1.15s\tremaining: 3.1s\n",
            "27:\ttotal: 1.18s\tremaining: 3.04s\n",
            "28:\ttotal: 1.23s\tremaining: 3s\n",
            "29:\ttotal: 1.26s\tremaining: 2.95s\n",
            "30:\ttotal: 1.3s\tremaining: 2.9s\n",
            "31:\ttotal: 1.34s\tremaining: 2.86s\n",
            "32:\ttotal: 1.39s\tremaining: 2.82s\n",
            "33:\ttotal: 1.43s\tremaining: 2.78s\n",
            "34:\ttotal: 1.48s\tremaining: 2.75s\n",
            "35:\ttotal: 1.52s\tremaining: 2.71s\n",
            "36:\ttotal: 1.56s\tremaining: 2.66s\n",
            "37:\ttotal: 1.61s\tremaining: 2.62s\n",
            "38:\ttotal: 1.65s\tremaining: 2.58s\n",
            "39:\ttotal: 1.69s\tremaining: 2.54s\n",
            "40:\ttotal: 1.74s\tremaining: 2.5s\n",
            "41:\ttotal: 1.77s\tremaining: 2.45s\n",
            "42:\ttotal: 1.82s\tremaining: 2.41s\n",
            "43:\ttotal: 1.87s\tremaining: 2.38s\n",
            "44:\ttotal: 1.91s\tremaining: 2.34s\n",
            "45:\ttotal: 1.96s\tremaining: 2.3s\n",
            "46:\ttotal: 2s\tremaining: 2.25s\n",
            "47:\ttotal: 2.04s\tremaining: 2.21s\n",
            "48:\ttotal: 2.08s\tremaining: 2.16s\n",
            "49:\ttotal: 2.12s\tremaining: 2.12s\n",
            "50:\ttotal: 2.15s\tremaining: 2.07s\n",
            "51:\ttotal: 2.19s\tremaining: 2.02s\n",
            "52:\ttotal: 2.24s\tremaining: 1.98s\n",
            "53:\ttotal: 2.27s\tremaining: 1.94s\n",
            "54:\ttotal: 2.32s\tremaining: 1.9s\n",
            "55:\ttotal: 2.35s\tremaining: 1.85s\n",
            "56:\ttotal: 2.39s\tremaining: 1.8s\n",
            "57:\ttotal: 2.42s\tremaining: 1.76s\n",
            "58:\ttotal: 2.47s\tremaining: 1.71s\n",
            "59:\ttotal: 2.52s\tremaining: 1.68s\n",
            "60:\ttotal: 2.56s\tremaining: 1.64s\n",
            "61:\ttotal: 2.6s\tremaining: 1.59s\n",
            "62:\ttotal: 2.64s\tremaining: 1.55s\n",
            "63:\ttotal: 2.68s\tremaining: 1.51s\n",
            "64:\ttotal: 2.72s\tremaining: 1.46s\n",
            "65:\ttotal: 2.76s\tremaining: 1.42s\n",
            "66:\ttotal: 2.81s\tremaining: 1.38s\n",
            "67:\ttotal: 2.85s\tremaining: 1.34s\n",
            "68:\ttotal: 2.88s\tremaining: 1.3s\n",
            "69:\ttotal: 2.93s\tremaining: 1.25s\n",
            "70:\ttotal: 2.97s\tremaining: 1.21s\n",
            "71:\ttotal: 3.02s\tremaining: 1.17s\n",
            "72:\ttotal: 3.06s\tremaining: 1.13s\n",
            "73:\ttotal: 3.1s\tremaining: 1.09s\n",
            "74:\ttotal: 3.15s\tremaining: 1.05s\n",
            "75:\ttotal: 3.19s\tremaining: 1.01s\n",
            "76:\ttotal: 3.23s\tremaining: 965ms\n",
            "77:\ttotal: 3.28s\tremaining: 924ms\n",
            "78:\ttotal: 3.32s\tremaining: 882ms\n",
            "79:\ttotal: 3.36s\tremaining: 841ms\n",
            "80:\ttotal: 3.4s\tremaining: 799ms\n",
            "81:\ttotal: 3.45s\tremaining: 757ms\n",
            "82:\ttotal: 3.49s\tremaining: 715ms\n",
            "83:\ttotal: 3.54s\tremaining: 674ms\n",
            "84:\ttotal: 3.58s\tremaining: 632ms\n",
            "85:\ttotal: 3.62s\tremaining: 589ms\n",
            "86:\ttotal: 3.66s\tremaining: 547ms\n",
            "87:\ttotal: 3.7s\tremaining: 505ms\n",
            "88:\ttotal: 3.74s\tremaining: 463ms\n",
            "89:\ttotal: 3.79s\tremaining: 421ms\n",
            "90:\ttotal: 3.84s\tremaining: 379ms\n",
            "91:\ttotal: 3.88s\tremaining: 337ms\n",
            "92:\ttotal: 3.92s\tremaining: 295ms\n",
            "93:\ttotal: 3.96s\tremaining: 253ms\n",
            "94:\ttotal: 4s\tremaining: 210ms\n",
            "95:\ttotal: 4.04s\tremaining: 168ms\n",
            "96:\ttotal: 4.08s\tremaining: 126ms\n",
            "97:\ttotal: 4.12s\tremaining: 84ms\n",
            "98:\ttotal: 4.15s\tremaining: 41.9ms\n",
            "99:\ttotal: 4.19s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:\ttotal: 41.9ms\tremaining: 4.15s\n",
            "1:\ttotal: 81ms\tremaining: 3.97s\n",
            "2:\ttotal: 119ms\tremaining: 3.83s\n",
            "3:\ttotal: 159ms\tremaining: 3.81s\n",
            "4:\ttotal: 198ms\tremaining: 3.76s\n",
            "5:\ttotal: 239ms\tremaining: 3.74s\n",
            "6:\ttotal: 286ms\tremaining: 3.8s\n",
            "7:\ttotal: 324ms\tremaining: 3.73s\n",
            "8:\ttotal: 363ms\tremaining: 3.67s\n",
            "9:\ttotal: 401ms\tremaining: 3.61s\n",
            "10:\ttotal: 443ms\tremaining: 3.58s\n",
            "11:\ttotal: 486ms\tremaining: 3.57s\n",
            "12:\ttotal: 534ms\tremaining: 3.57s\n",
            "13:\ttotal: 574ms\tremaining: 3.52s\n",
            "14:\ttotal: 609ms\tremaining: 3.45s\n",
            "15:\ttotal: 650ms\tremaining: 3.41s\n",
            "16:\ttotal: 695ms\tremaining: 3.4s\n",
            "17:\ttotal: 740ms\tremaining: 3.37s\n",
            "18:\ttotal: 778ms\tremaining: 3.32s\n",
            "19:\ttotal: 820ms\tremaining: 3.28s\n",
            "20:\ttotal: 863ms\tremaining: 3.25s\n",
            "21:\ttotal: 906ms\tremaining: 3.21s\n",
            "22:\ttotal: 948ms\tremaining: 3.17s\n",
            "23:\ttotal: 997ms\tremaining: 3.16s\n",
            "24:\ttotal: 1.04s\tremaining: 3.12s\n",
            "25:\ttotal: 1.08s\tremaining: 3.07s\n",
            "26:\ttotal: 1.12s\tremaining: 3.03s\n",
            "27:\ttotal: 1.16s\tremaining: 2.99s\n",
            "28:\ttotal: 1.21s\tremaining: 2.95s\n",
            "29:\ttotal: 1.25s\tremaining: 2.91s\n",
            "30:\ttotal: 1.29s\tremaining: 2.88s\n",
            "31:\ttotal: 1.34s\tremaining: 2.84s\n",
            "32:\ttotal: 1.38s\tremaining: 2.8s\n",
            "33:\ttotal: 1.42s\tremaining: 2.75s\n",
            "34:\ttotal: 1.46s\tremaining: 2.7s\n",
            "35:\ttotal: 1.49s\tremaining: 2.65s\n",
            "36:\ttotal: 1.53s\tremaining: 2.61s\n",
            "37:\ttotal: 1.58s\tremaining: 2.58s\n",
            "38:\ttotal: 1.63s\tremaining: 2.54s\n",
            "39:\ttotal: 1.67s\tremaining: 2.5s\n",
            "40:\ttotal: 1.71s\tremaining: 2.46s\n",
            "41:\ttotal: 1.74s\tremaining: 2.41s\n",
            "42:\ttotal: 1.79s\tremaining: 2.37s\n",
            "43:\ttotal: 1.83s\tremaining: 2.33s\n",
            "44:\ttotal: 1.86s\tremaining: 2.28s\n",
            "45:\ttotal: 1.9s\tremaining: 2.24s\n",
            "46:\ttotal: 1.94s\tremaining: 2.19s\n",
            "47:\ttotal: 1.99s\tremaining: 2.15s\n",
            "48:\ttotal: 2.04s\tremaining: 2.13s\n",
            "49:\ttotal: 2.08s\tremaining: 2.08s\n",
            "50:\ttotal: 2.13s\tremaining: 2.04s\n",
            "51:\ttotal: 2.17s\tremaining: 2s\n",
            "52:\ttotal: 2.21s\tremaining: 1.96s\n",
            "53:\ttotal: 2.26s\tremaining: 1.92s\n",
            "54:\ttotal: 2.29s\tremaining: 1.88s\n",
            "55:\ttotal: 2.34s\tremaining: 1.83s\n",
            "56:\ttotal: 2.38s\tremaining: 1.79s\n",
            "57:\ttotal: 2.42s\tremaining: 1.75s\n",
            "58:\ttotal: 2.47s\tremaining: 1.71s\n",
            "59:\ttotal: 2.51s\tremaining: 1.67s\n",
            "60:\ttotal: 2.55s\tremaining: 1.63s\n",
            "61:\ttotal: 2.59s\tremaining: 1.59s\n",
            "62:\ttotal: 2.64s\tremaining: 1.55s\n",
            "63:\ttotal: 2.68s\tremaining: 1.51s\n",
            "64:\ttotal: 2.72s\tremaining: 1.46s\n",
            "65:\ttotal: 2.76s\tremaining: 1.42s\n",
            "66:\ttotal: 2.8s\tremaining: 1.38s\n",
            "67:\ttotal: 2.84s\tremaining: 1.33s\n",
            "68:\ttotal: 2.88s\tremaining: 1.29s\n",
            "69:\ttotal: 2.92s\tremaining: 1.25s\n",
            "70:\ttotal: 2.96s\tremaining: 1.21s\n",
            "71:\ttotal: 3s\tremaining: 1.17s\n",
            "72:\ttotal: 3.05s\tremaining: 1.13s\n",
            "73:\ttotal: 3.09s\tremaining: 1.09s\n",
            "74:\ttotal: 3.13s\tremaining: 1.04s\n",
            "75:\ttotal: 3.17s\tremaining: 1s\n",
            "76:\ttotal: 3.21s\tremaining: 959ms\n",
            "77:\ttotal: 3.25s\tremaining: 917ms\n",
            "78:\ttotal: 3.29s\tremaining: 874ms\n",
            "79:\ttotal: 3.33s\tremaining: 834ms\n",
            "80:\ttotal: 3.37s\tremaining: 791ms\n",
            "81:\ttotal: 3.42s\tremaining: 750ms\n",
            "82:\ttotal: 3.45s\tremaining: 708ms\n",
            "83:\ttotal: 3.5s\tremaining: 666ms\n",
            "84:\ttotal: 3.54s\tremaining: 625ms\n",
            "85:\ttotal: 3.59s\tremaining: 584ms\n",
            "86:\ttotal: 3.63s\tremaining: 542ms\n",
            "87:\ttotal: 3.67s\tremaining: 500ms\n",
            "88:\ttotal: 3.7s\tremaining: 457ms\n",
            "89:\ttotal: 3.74s\tremaining: 415ms\n",
            "90:\ttotal: 3.78s\tremaining: 374ms\n",
            "91:\ttotal: 3.82s\tremaining: 333ms\n",
            "92:\ttotal: 3.87s\tremaining: 291ms\n",
            "93:\ttotal: 3.91s\tremaining: 249ms\n",
            "94:\ttotal: 3.95s\tremaining: 208ms\n",
            "95:\ttotal: 3.99s\tremaining: 166ms\n",
            "96:\ttotal: 4.04s\tremaining: 125ms\n",
            "97:\ttotal: 4.08s\tremaining: 83.4ms\n",
            "98:\ttotal: 4.13s\tremaining: 41.7ms\n",
            "99:\ttotal: 4.17s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:\ttotal: 41.2ms\tremaining: 4.08s\n",
            "1:\ttotal: 79.1ms\tremaining: 3.88s\n",
            "2:\ttotal: 123ms\tremaining: 3.97s\n",
            "3:\ttotal: 162ms\tremaining: 3.89s\n",
            "4:\ttotal: 201ms\tremaining: 3.83s\n",
            "5:\ttotal: 240ms\tremaining: 3.77s\n",
            "6:\ttotal: 288ms\tremaining: 3.82s\n",
            "7:\ttotal: 337ms\tremaining: 3.88s\n",
            "8:\ttotal: 382ms\tremaining: 3.86s\n",
            "9:\ttotal: 423ms\tremaining: 3.81s\n",
            "10:\ttotal: 461ms\tremaining: 3.73s\n",
            "11:\ttotal: 503ms\tremaining: 3.69s\n",
            "12:\ttotal: 552ms\tremaining: 3.7s\n",
            "13:\ttotal: 593ms\tremaining: 3.64s\n",
            "14:\ttotal: 631ms\tremaining: 3.58s\n",
            "15:\ttotal: 674ms\tremaining: 3.54s\n",
            "16:\ttotal: 719ms\tremaining: 3.51s\n",
            "17:\ttotal: 760ms\tremaining: 3.46s\n",
            "18:\ttotal: 798ms\tremaining: 3.4s\n",
            "19:\ttotal: 837ms\tremaining: 3.35s\n",
            "20:\ttotal: 876ms\tremaining: 3.29s\n",
            "21:\ttotal: 914ms\tremaining: 3.24s\n",
            "22:\ttotal: 960ms\tremaining: 3.21s\n",
            "23:\ttotal: 999ms\tremaining: 3.16s\n",
            "24:\ttotal: 1.04s\tremaining: 3.11s\n",
            "25:\ttotal: 1.07s\tremaining: 3.06s\n",
            "26:\ttotal: 1.12s\tremaining: 3.02s\n",
            "27:\ttotal: 1.16s\tremaining: 2.98s\n",
            "28:\ttotal: 1.2s\tremaining: 2.94s\n",
            "29:\ttotal: 1.24s\tremaining: 2.9s\n",
            "30:\ttotal: 1.28s\tremaining: 2.85s\n",
            "31:\ttotal: 1.32s\tremaining: 2.81s\n",
            "32:\ttotal: 1.36s\tremaining: 2.77s\n",
            "33:\ttotal: 1.41s\tremaining: 2.73s\n",
            "34:\ttotal: 1.45s\tremaining: 2.7s\n",
            "35:\ttotal: 1.49s\tremaining: 2.65s\n",
            "36:\ttotal: 1.55s\tremaining: 2.63s\n",
            "37:\ttotal: 1.59s\tremaining: 2.59s\n",
            "38:\ttotal: 1.63s\tremaining: 2.55s\n",
            "39:\ttotal: 1.67s\tremaining: 2.5s\n",
            "40:\ttotal: 1.71s\tremaining: 2.46s\n",
            "41:\ttotal: 1.74s\tremaining: 2.41s\n",
            "42:\ttotal: 1.78s\tremaining: 2.37s\n",
            "43:\ttotal: 1.82s\tremaining: 2.32s\n",
            "44:\ttotal: 1.87s\tremaining: 2.28s\n",
            "45:\ttotal: 1.91s\tremaining: 2.24s\n",
            "46:\ttotal: 1.95s\tremaining: 2.2s\n",
            "47:\ttotal: 1.99s\tremaining: 2.16s\n",
            "48:\ttotal: 2.03s\tremaining: 2.12s\n",
            "49:\ttotal: 2.08s\tremaining: 2.08s\n",
            "50:\ttotal: 2.12s\tremaining: 2.04s\n",
            "51:\ttotal: 2.15s\tremaining: 1.99s\n",
            "52:\ttotal: 2.19s\tremaining: 1.94s\n",
            "53:\ttotal: 2.23s\tremaining: 1.9s\n",
            "54:\ttotal: 2.27s\tremaining: 1.85s\n",
            "55:\ttotal: 2.31s\tremaining: 1.81s\n",
            "56:\ttotal: 2.35s\tremaining: 1.77s\n",
            "57:\ttotal: 2.39s\tremaining: 1.73s\n",
            "58:\ttotal: 2.43s\tremaining: 1.69s\n",
            "59:\ttotal: 2.46s\tremaining: 1.64s\n",
            "60:\ttotal: 2.5s\tremaining: 1.6s\n",
            "61:\ttotal: 2.55s\tremaining: 1.56s\n",
            "62:\ttotal: 2.6s\tremaining: 1.53s\n",
            "63:\ttotal: 2.64s\tremaining: 1.48s\n",
            "64:\ttotal: 2.68s\tremaining: 1.44s\n",
            "65:\ttotal: 2.71s\tremaining: 1.4s\n",
            "66:\ttotal: 2.76s\tremaining: 1.36s\n",
            "67:\ttotal: 2.8s\tremaining: 1.32s\n",
            "68:\ttotal: 2.84s\tremaining: 1.27s\n",
            "69:\ttotal: 2.88s\tremaining: 1.23s\n",
            "70:\ttotal: 2.91s\tremaining: 1.19s\n",
            "71:\ttotal: 2.95s\tremaining: 1.15s\n",
            "72:\ttotal: 3s\tremaining: 1.11s\n",
            "73:\ttotal: 3.03s\tremaining: 1.07s\n",
            "74:\ttotal: 3.08s\tremaining: 1.03s\n",
            "75:\ttotal: 3.12s\tremaining: 986ms\n",
            "76:\ttotal: 3.17s\tremaining: 946ms\n",
            "77:\ttotal: 3.21s\tremaining: 907ms\n",
            "78:\ttotal: 3.26s\tremaining: 866ms\n",
            "79:\ttotal: 3.3s\tremaining: 824ms\n",
            "80:\ttotal: 3.34s\tremaining: 784ms\n",
            "81:\ttotal: 3.38s\tremaining: 742ms\n",
            "82:\ttotal: 3.43s\tremaining: 702ms\n",
            "83:\ttotal: 3.47s\tremaining: 660ms\n",
            "84:\ttotal: 3.51s\tremaining: 619ms\n",
            "85:\ttotal: 3.55s\tremaining: 578ms\n",
            "86:\ttotal: 3.59s\tremaining: 537ms\n",
            "87:\ttotal: 3.64s\tremaining: 496ms\n",
            "88:\ttotal: 3.68s\tremaining: 455ms\n",
            "89:\ttotal: 3.72s\tremaining: 413ms\n",
            "90:\ttotal: 3.76s\tremaining: 371ms\n",
            "91:\ttotal: 3.79s\tremaining: 330ms\n",
            "92:\ttotal: 3.83s\tremaining: 288ms\n",
            "93:\ttotal: 3.88s\tremaining: 247ms\n",
            "94:\ttotal: 3.92s\tremaining: 206ms\n",
            "95:\ttotal: 3.96s\tremaining: 165ms\n",
            "96:\ttotal: 4s\tremaining: 124ms\n",
            "97:\ttotal: 4.04s\tremaining: 82.5ms\n",
            "98:\ttotal: 4.08s\tremaining: 41.2ms\n",
            "99:\ttotal: 4.13s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:\ttotal: 51.9ms\tremaining: 5.14s\n",
            "1:\ttotal: 124ms\tremaining: 6.09s\n",
            "2:\ttotal: 180ms\tremaining: 5.83s\n",
            "3:\ttotal: 228ms\tremaining: 5.46s\n",
            "4:\ttotal: 285ms\tremaining: 5.41s\n",
            "5:\ttotal: 339ms\tremaining: 5.31s\n",
            "6:\ttotal: 386ms\tremaining: 5.13s\n",
            "7:\ttotal: 435ms\tremaining: 5s\n",
            "8:\ttotal: 488ms\tremaining: 4.94s\n",
            "9:\ttotal: 541ms\tremaining: 4.87s\n",
            "10:\ttotal: 593ms\tremaining: 4.8s\n",
            "11:\ttotal: 643ms\tremaining: 4.71s\n",
            "12:\ttotal: 696ms\tremaining: 4.66s\n",
            "13:\ttotal: 752ms\tremaining: 4.62s\n",
            "14:\ttotal: 805ms\tremaining: 4.56s\n",
            "15:\ttotal: 853ms\tremaining: 4.48s\n",
            "16:\ttotal: 913ms\tremaining: 4.46s\n",
            "17:\ttotal: 968ms\tremaining: 4.41s\n",
            "18:\ttotal: 1.01s\tremaining: 4.32s\n",
            "19:\ttotal: 1.07s\tremaining: 4.27s\n",
            "20:\ttotal: 1.13s\tremaining: 4.26s\n",
            "21:\ttotal: 1.18s\tremaining: 4.2s\n",
            "22:\ttotal: 1.23s\tremaining: 4.13s\n",
            "23:\ttotal: 1.28s\tremaining: 4.06s\n",
            "24:\ttotal: 1.34s\tremaining: 4.02s\n",
            "25:\ttotal: 1.39s\tremaining: 3.95s\n",
            "26:\ttotal: 1.44s\tremaining: 3.88s\n",
            "27:\ttotal: 1.48s\tremaining: 3.81s\n",
            "28:\ttotal: 1.53s\tremaining: 3.76s\n",
            "29:\ttotal: 1.59s\tremaining: 3.71s\n",
            "30:\ttotal: 1.65s\tremaining: 3.66s\n",
            "31:\ttotal: 1.69s\tremaining: 3.6s\n",
            "32:\ttotal: 1.74s\tremaining: 3.54s\n",
            "33:\ttotal: 1.79s\tremaining: 3.48s\n",
            "34:\ttotal: 1.85s\tremaining: 3.44s\n",
            "35:\ttotal: 1.9s\tremaining: 3.38s\n",
            "36:\ttotal: 1.95s\tremaining: 3.32s\n",
            "37:\ttotal: 2.01s\tremaining: 3.29s\n",
            "38:\ttotal: 2.06s\tremaining: 3.23s\n",
            "39:\ttotal: 2.11s\tremaining: 3.17s\n",
            "40:\ttotal: 2.17s\tremaining: 3.12s\n",
            "41:\ttotal: 2.22s\tremaining: 3.07s\n",
            "42:\ttotal: 2.28s\tremaining: 3.02s\n",
            "43:\ttotal: 2.33s\tremaining: 2.97s\n",
            "44:\ttotal: 2.38s\tremaining: 2.91s\n",
            "45:\ttotal: 2.43s\tremaining: 2.86s\n",
            "46:\ttotal: 2.48s\tremaining: 2.8s\n",
            "47:\ttotal: 2.54s\tremaining: 2.75s\n",
            "48:\ttotal: 2.59s\tremaining: 2.69s\n",
            "49:\ttotal: 2.65s\tremaining: 2.65s\n",
            "50:\ttotal: 2.69s\tremaining: 2.58s\n",
            "51:\ttotal: 2.74s\tremaining: 2.53s\n",
            "52:\ttotal: 2.79s\tremaining: 2.48s\n",
            "53:\ttotal: 2.84s\tremaining: 2.42s\n",
            "54:\ttotal: 2.89s\tremaining: 2.37s\n",
            "55:\ttotal: 2.94s\tremaining: 2.31s\n",
            "56:\ttotal: 3s\tremaining: 2.26s\n",
            "57:\ttotal: 3.04s\tremaining: 2.2s\n",
            "58:\ttotal: 3.09s\tremaining: 2.15s\n",
            "59:\ttotal: 3.14s\tremaining: 2.1s\n",
            "60:\ttotal: 3.21s\tremaining: 2.05s\n",
            "61:\ttotal: 3.26s\tremaining: 2s\n",
            "62:\ttotal: 3.31s\tremaining: 1.94s\n",
            "63:\ttotal: 3.36s\tremaining: 1.89s\n",
            "64:\ttotal: 3.4s\tremaining: 1.83s\n",
            "65:\ttotal: 3.45s\tremaining: 1.78s\n",
            "66:\ttotal: 3.5s\tremaining: 1.72s\n",
            "67:\ttotal: 3.55s\tremaining: 1.67s\n",
            "68:\ttotal: 3.6s\tremaining: 1.62s\n",
            "69:\ttotal: 3.65s\tremaining: 1.57s\n",
            "70:\ttotal: 3.71s\tremaining: 1.51s\n",
            "71:\ttotal: 3.76s\tremaining: 1.46s\n",
            "72:\ttotal: 3.8s\tremaining: 1.41s\n",
            "73:\ttotal: 3.86s\tremaining: 1.36s\n",
            "74:\ttotal: 3.91s\tremaining: 1.3s\n",
            "75:\ttotal: 3.96s\tremaining: 1.25s\n",
            "76:\ttotal: 4.01s\tremaining: 1.2s\n",
            "77:\ttotal: 4.06s\tremaining: 1.15s\n",
            "78:\ttotal: 4.12s\tremaining: 1.09s\n",
            "79:\ttotal: 4.17s\tremaining: 1.04s\n",
            "80:\ttotal: 4.23s\tremaining: 992ms\n",
            "81:\ttotal: 4.28s\tremaining: 939ms\n",
            "82:\ttotal: 4.32s\tremaining: 885ms\n",
            "83:\ttotal: 4.38s\tremaining: 834ms\n",
            "84:\ttotal: 4.42s\tremaining: 780ms\n",
            "85:\ttotal: 4.47s\tremaining: 728ms\n",
            "86:\ttotal: 4.52s\tremaining: 675ms\n",
            "87:\ttotal: 4.57s\tremaining: 623ms\n",
            "88:\ttotal: 4.62s\tremaining: 570ms\n",
            "89:\ttotal: 4.67s\tremaining: 518ms\n",
            "90:\ttotal: 4.72s\tremaining: 467ms\n",
            "91:\ttotal: 4.77s\tremaining: 414ms\n",
            "92:\ttotal: 4.81s\tremaining: 362ms\n",
            "93:\ttotal: 4.87s\tremaining: 311ms\n",
            "94:\ttotal: 4.93s\tremaining: 260ms\n",
            "95:\ttotal: 4.99s\tremaining: 208ms\n",
            "96:\ttotal: 5.04s\tremaining: 156ms\n",
            "97:\ttotal: 5.09s\tremaining: 104ms\n",
            "98:\ttotal: 5.15s\tremaining: 52ms\n",
            "99:\ttotal: 5.21s\tremaining: 0us\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0:\ttotal: 52.2ms\tremaining: 5.16s\n",
            "1:\ttotal: 97.3ms\tremaining: 4.77s\n",
            "2:\ttotal: 144ms\tremaining: 4.67s\n",
            "3:\ttotal: 196ms\tremaining: 4.71s\n",
            "4:\ttotal: 247ms\tremaining: 4.68s\n",
            "5:\ttotal: 298ms\tremaining: 4.66s\n",
            "6:\ttotal: 348ms\tremaining: 4.62s\n",
            "7:\ttotal: 402ms\tremaining: 4.62s\n",
            "8:\ttotal: 455ms\tremaining: 4.6s\n",
            "9:\ttotal: 515ms\tremaining: 4.64s\n",
            "10:\ttotal: 571ms\tremaining: 4.62s\n",
            "11:\ttotal: 617ms\tremaining: 4.52s\n",
            "12:\ttotal: 682ms\tremaining: 4.57s\n",
            "13:\ttotal: 736ms\tremaining: 4.52s\n",
            "14:\ttotal: 789ms\tremaining: 4.47s\n",
            "15:\ttotal: 841ms\tremaining: 4.41s\n",
            "16:\ttotal: 887ms\tremaining: 4.33s\n",
            "17:\ttotal: 934ms\tremaining: 4.25s\n",
            "18:\ttotal: 986ms\tremaining: 4.21s\n",
            "19:\ttotal: 1.04s\tremaining: 4.16s\n",
            "20:\ttotal: 1.09s\tremaining: 4.11s\n",
            "21:\ttotal: 1.14s\tremaining: 4.04s\n",
            "22:\ttotal: 1.19s\tremaining: 3.97s\n",
            "23:\ttotal: 1.24s\tremaining: 3.92s\n",
            "24:\ttotal: 1.29s\tremaining: 3.86s\n",
            "25:\ttotal: 1.33s\tremaining: 3.8s\n",
            "26:\ttotal: 1.39s\tremaining: 3.75s\n",
            "27:\ttotal: 1.44s\tremaining: 3.71s\n",
            "28:\ttotal: 1.49s\tremaining: 3.66s\n",
            "29:\ttotal: 1.54s\tremaining: 3.59s\n",
            "30:\ttotal: 1.59s\tremaining: 3.55s\n",
            "31:\ttotal: 1.66s\tremaining: 3.54s\n",
            "32:\ttotal: 1.72s\tremaining: 3.5s\n",
            "33:\ttotal: 1.77s\tremaining: 3.44s\n",
            "34:\ttotal: 1.82s\tremaining: 3.39s\n",
            "35:\ttotal: 1.88s\tremaining: 3.34s\n",
            "36:\ttotal: 1.93s\tremaining: 3.29s\n",
            "37:\ttotal: 1.98s\tremaining: 3.23s\n",
            "38:\ttotal: 2.04s\tremaining: 3.19s\n",
            "39:\ttotal: 2.09s\tremaining: 3.14s\n",
            "40:\ttotal: 2.14s\tremaining: 3.08s\n",
            "41:\ttotal: 2.2s\tremaining: 3.03s\n",
            "42:\ttotal: 2.25s\tremaining: 2.98s\n",
            "43:\ttotal: 2.31s\tremaining: 2.94s\n",
            "44:\ttotal: 2.37s\tremaining: 2.89s\n",
            "45:\ttotal: 2.42s\tremaining: 2.84s\n",
            "46:\ttotal: 2.47s\tremaining: 2.79s\n",
            "47:\ttotal: 2.52s\tremaining: 2.73s\n",
            "48:\ttotal: 2.57s\tremaining: 2.68s\n",
            "49:\ttotal: 2.63s\tremaining: 2.63s\n",
            "50:\ttotal: 2.68s\tremaining: 2.58s\n",
            "51:\ttotal: 2.74s\tremaining: 2.53s\n",
            "52:\ttotal: 2.79s\tremaining: 2.48s\n",
            "53:\ttotal: 2.85s\tremaining: 2.43s\n",
            "54:\ttotal: 2.9s\tremaining: 2.37s\n",
            "55:\ttotal: 2.96s\tremaining: 2.33s\n",
            "56:\ttotal: 3.02s\tremaining: 2.28s\n",
            "57:\ttotal: 3.08s\tremaining: 2.23s\n",
            "58:\ttotal: 3.13s\tremaining: 2.18s\n",
            "59:\ttotal: 3.19s\tremaining: 2.13s\n",
            "60:\ttotal: 3.24s\tremaining: 2.07s\n",
            "61:\ttotal: 3.3s\tremaining: 2.02s\n",
            "62:\ttotal: 3.35s\tremaining: 1.97s\n",
            "63:\ttotal: 3.4s\tremaining: 1.92s\n",
            "64:\ttotal: 3.46s\tremaining: 1.86s\n",
            "65:\ttotal: 3.51s\tremaining: 1.81s\n",
            "66:\ttotal: 3.56s\tremaining: 1.75s\n",
            "67:\ttotal: 3.62s\tremaining: 1.7s\n",
            "68:\ttotal: 3.67s\tremaining: 1.65s\n",
            "69:\ttotal: 3.73s\tremaining: 1.6s\n",
            "70:\ttotal: 3.79s\tremaining: 1.55s\n",
            "71:\ttotal: 3.85s\tremaining: 1.5s\n",
            "72:\ttotal: 3.9s\tremaining: 1.44s\n",
            "73:\ttotal: 3.96s\tremaining: 1.39s\n",
            "74:\ttotal: 4.02s\tremaining: 1.34s\n",
            "75:\ttotal: 4.08s\tremaining: 1.29s\n",
            "76:\ttotal: 4.14s\tremaining: 1.24s\n",
            "77:\ttotal: 4.2s\tremaining: 1.18s\n",
            "78:\ttotal: 4.24s\tremaining: 1.13s\n",
            "79:\ttotal: 4.3s\tremaining: 1.07s\n",
            "80:\ttotal: 4.36s\tremaining: 1.02s\n",
            "81:\ttotal: 4.41s\tremaining: 969ms\n",
            "82:\ttotal: 4.46s\tremaining: 915ms\n",
            "83:\ttotal: 4.52s\tremaining: 861ms\n",
            "84:\ttotal: 4.57s\tremaining: 806ms\n",
            "85:\ttotal: 4.62s\tremaining: 752ms\n",
            "86:\ttotal: 4.68s\tremaining: 699ms\n",
            "87:\ttotal: 4.75s\tremaining: 648ms\n",
            "88:\ttotal: 4.8s\tremaining: 594ms\n",
            "89:\ttotal: 4.86s\tremaining: 540ms\n",
            "90:\ttotal: 4.91s\tremaining: 485ms\n",
            "91:\ttotal: 4.97s\tremaining: 432ms\n",
            "92:\ttotal: 5.03s\tremaining: 378ms\n",
            "93:\ttotal: 5.07s\tremaining: 324ms\n",
            "94:\ttotal: 5.13s\tremaining: 270ms\n",
            "95:\ttotal: 5.19s\tremaining: 216ms\n",
            "96:\ttotal: 5.24s\tremaining: 162ms\n",
            "97:\ttotal: 5.29s\tremaining: 108ms\n",
            "98:\ttotal: 5.34s\tremaining: 54ms\n",
            "99:\ttotal: 5.4s\tremaining: 0us\n",
            "    ----\n",
            "    MEAN:     [0.76378308] + [0.01924792]\n",
            "    FULL:     [0.76268529]\n",
            "\n",
            "    Fitting on full train set...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0:\ttotal: 56.2ms\tremaining: 5.57s\n",
            "1:\ttotal: 112ms\tremaining: 5.5s\n",
            "2:\ttotal: 168ms\tremaining: 5.44s\n",
            "3:\ttotal: 220ms\tremaining: 5.29s\n",
            "4:\ttotal: 279ms\tremaining: 5.29s\n",
            "5:\ttotal: 332ms\tremaining: 5.2s\n",
            "6:\ttotal: 382ms\tremaining: 5.07s\n",
            "7:\ttotal: 430ms\tremaining: 4.95s\n",
            "8:\ttotal: 490ms\tremaining: 4.95s\n",
            "9:\ttotal: 540ms\tremaining: 4.86s\n",
            "10:\ttotal: 592ms\tremaining: 4.79s\n",
            "11:\ttotal: 640ms\tremaining: 4.69s\n",
            "12:\ttotal: 689ms\tremaining: 4.61s\n",
            "13:\ttotal: 746ms\tremaining: 4.58s\n",
            "14:\ttotal: 800ms\tremaining: 4.53s\n",
            "15:\ttotal: 854ms\tremaining: 4.48s\n",
            "16:\ttotal: 902ms\tremaining: 4.4s\n",
            "17:\ttotal: 969ms\tremaining: 4.41s\n",
            "18:\ttotal: 1.02s\tremaining: 4.34s\n",
            "19:\ttotal: 1.07s\tremaining: 4.29s\n",
            "20:\ttotal: 1.12s\tremaining: 4.22s\n",
            "21:\ttotal: 1.18s\tremaining: 4.19s\n",
            "22:\ttotal: 1.23s\tremaining: 4.13s\n",
            "23:\ttotal: 1.28s\tremaining: 4.05s\n",
            "24:\ttotal: 1.33s\tremaining: 3.99s\n",
            "25:\ttotal: 1.4s\tremaining: 3.97s\n",
            "26:\ttotal: 1.46s\tremaining: 3.93s\n",
            "27:\ttotal: 1.51s\tremaining: 3.88s\n",
            "28:\ttotal: 1.56s\tremaining: 3.82s\n",
            "29:\ttotal: 1.62s\tremaining: 3.77s\n",
            "30:\ttotal: 1.67s\tremaining: 3.72s\n",
            "31:\ttotal: 1.73s\tremaining: 3.67s\n",
            "32:\ttotal: 1.77s\tremaining: 3.6s\n",
            "33:\ttotal: 1.83s\tremaining: 3.55s\n",
            "34:\ttotal: 1.89s\tremaining: 3.51s\n",
            "35:\ttotal: 1.95s\tremaining: 3.46s\n",
            "36:\ttotal: 2s\tremaining: 3.41s\n",
            "37:\ttotal: 2.06s\tremaining: 3.35s\n",
            "38:\ttotal: 2.11s\tremaining: 3.3s\n",
            "39:\ttotal: 2.16s\tremaining: 3.24s\n",
            "40:\ttotal: 2.21s\tremaining: 3.19s\n",
            "41:\ttotal: 2.27s\tremaining: 3.14s\n",
            "42:\ttotal: 2.33s\tremaining: 3.09s\n",
            "43:\ttotal: 2.38s\tremaining: 3.03s\n",
            "44:\ttotal: 2.43s\tremaining: 2.97s\n",
            "45:\ttotal: 2.49s\tremaining: 2.92s\n",
            "46:\ttotal: 2.54s\tremaining: 2.87s\n",
            "47:\ttotal: 2.59s\tremaining: 2.81s\n",
            "48:\ttotal: 2.65s\tremaining: 2.75s\n",
            "49:\ttotal: 2.71s\tremaining: 2.71s\n",
            "50:\ttotal: 2.76s\tremaining: 2.65s\n",
            "51:\ttotal: 2.81s\tremaining: 2.6s\n",
            "52:\ttotal: 2.86s\tremaining: 2.54s\n",
            "53:\ttotal: 2.92s\tremaining: 2.49s\n",
            "54:\ttotal: 2.98s\tremaining: 2.44s\n",
            "55:\ttotal: 3.03s\tremaining: 2.38s\n",
            "56:\ttotal: 3.09s\tremaining: 2.33s\n",
            "57:\ttotal: 3.14s\tremaining: 2.27s\n",
            "58:\ttotal: 3.2s\tremaining: 2.22s\n",
            "59:\ttotal: 3.25s\tremaining: 2.17s\n",
            "60:\ttotal: 3.3s\tremaining: 2.11s\n",
            "61:\ttotal: 3.35s\tremaining: 2.06s\n",
            "62:\ttotal: 3.4s\tremaining: 2s\n",
            "63:\ttotal: 3.45s\tremaining: 1.94s\n",
            "64:\ttotal: 3.5s\tremaining: 1.89s\n",
            "65:\ttotal: 3.56s\tremaining: 1.83s\n",
            "66:\ttotal: 3.61s\tremaining: 1.78s\n",
            "67:\ttotal: 3.67s\tremaining: 1.73s\n",
            "68:\ttotal: 3.72s\tremaining: 1.67s\n",
            "69:\ttotal: 3.78s\tremaining: 1.62s\n",
            "70:\ttotal: 3.83s\tremaining: 1.56s\n",
            "71:\ttotal: 3.88s\tremaining: 1.51s\n",
            "72:\ttotal: 3.93s\tremaining: 1.46s\n",
            "73:\ttotal: 4s\tremaining: 1.41s\n",
            "74:\ttotal: 4.06s\tremaining: 1.35s\n",
            "75:\ttotal: 4.11s\tremaining: 1.3s\n",
            "76:\ttotal: 4.17s\tremaining: 1.24s\n",
            "77:\ttotal: 4.22s\tremaining: 1.19s\n",
            "78:\ttotal: 4.27s\tremaining: 1.14s\n",
            "79:\ttotal: 4.32s\tremaining: 1.08s\n",
            "80:\ttotal: 4.38s\tremaining: 1.03s\n",
            "81:\ttotal: 4.43s\tremaining: 973ms\n",
            "82:\ttotal: 4.49s\tremaining: 919ms\n",
            "83:\ttotal: 4.54s\tremaining: 865ms\n",
            "84:\ttotal: 4.59s\tremaining: 811ms\n",
            "85:\ttotal: 4.65s\tremaining: 757ms\n",
            "86:\ttotal: 4.7s\tremaining: 703ms\n",
            "87:\ttotal: 4.75s\tremaining: 648ms\n",
            "88:\ttotal: 4.8s\tremaining: 593ms\n",
            "89:\ttotal: 4.86s\tremaining: 540ms\n",
            "90:\ttotal: 4.91s\tremaining: 485ms\n",
            "91:\ttotal: 4.96s\tremaining: 431ms\n",
            "92:\ttotal: 5.02s\tremaining: 378ms\n",
            "93:\ttotal: 5.08s\tremaining: 324ms\n",
            "94:\ttotal: 5.13s\tremaining: 270ms\n",
            "95:\ttotal: 5.18s\tremaining: 216ms\n",
            "96:\ttotal: 5.23s\tremaining: 162ms\n",
            "97:\ttotal: 5.29s\tremaining: 108ms\n",
            "98:\ttotal: 5.34s\tremaining: 54ms\n",
            "99:\ttotal: 5.39s\tremaining: 0us\n",
            "Result was saved to [/content/gdrive/My Drive/santander_results/[2019.03.27].[21.14.02].232515.7f0aac.npy]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "McU0f1Ge8Acc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stacking Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "gXL1ZFDe5lqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1ca4551b-c6dc-451a-b5e0-5178ff8119e8"
      },
      "cell_type": "code",
      "source": [
        "help(StackingTransformer)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c761a67ff7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStackingTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'StackingTransformer' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "WMzNY7Bz8Cp-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specify steps of Pipeline\n",
        "pipe_models_1 = [ \n",
        "    ('gnb', GaussianNB()),\n",
        "    #('lg', LogisticRegression(random_state=0)),\n",
        "    #('nn', KerasClassifier(build_fn=dnn, epochs=2, batch_size=32, verbose=0, callbacks=[logger])),\n",
        "    #('nn', KerasClassifier(build_fn=dnn, epochs=2, batch_size=32, verbose=0)),\n",
        "    #('etc', ExtraTreesClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "    #('rfc', RandomForestClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "    ('xgb', XGBClassifier(**xgb_params)),           \n",
        "    ('lgbm', LGBMClassifier(**lgb_params)),\n",
        "    ('cb', CatBoostClassifier(**catboost_params))\n",
        "]\n",
        "pipe_models_2 = [ \n",
        "    #('gnb', GaussianNB()),\n",
        "    #('etc', ExtraTreesClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "    #('rfc', RandomForestClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "    ('xgb', XGBClassifier(**xgb_params)),           \n",
        "    ('lgbm', LGBMClassifier(**lgb_params)),\n",
        "    ('cb', CatBoostClassifier(**catboost_params))\n",
        "]\n",
        "pipe_models_3 = [ \n",
        "    #('gnb', GaussianNB()),\n",
        "    #('rfc', RandomForestClassifier(random_state=0, n_jobs=-1, n_estimators=100, max_depth=3)),\n",
        "    ('xgb', XGBClassifier(**xgb_params)),           \n",
        "    ('lgbm', LGBMClassifier(**lgb_params)),\n",
        "    #('cb', CatBoostClassifier(**catboost_params))\n",
        "]\n",
        "\n",
        "stack1 = StackingTransformer(pipe_models_1,                   # list of models\n",
        "                               #X_train, y_train, X_test,   # data\n",
        "                               regression=False,           # classification task (if you need \n",
        "                                                           #     regression - set to True)\n",
        "                               #mode='oof_pred',            # mode: oof for train set, fit on full \n",
        "                               variant='A',                            #     train and predict test set once\n",
        "                               needs_proba=True,           # predict probabilities (if you need \n",
        "                                                           #     class labels - set to False) \n",
        "                               ##save_dir='.',               # save result and log in current dir \n",
        "                               #save_dir=save_directory,                                 #     (to disable saving - set to None)\n",
        "                               metric=auc,            # metric: callable\n",
        "                               n_folds=5,                  # number of folds\n",
        "                               stratified=True,            # stratified split for folds\n",
        "                               shuffle=True,               # shuffle the data\n",
        "                               random_state=0,             # ensure reproducibility\n",
        "                               verbose=1)                  # print all info\n",
        "\n",
        "# stack2 = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "#                       n_estimators=100, max_depth=3)\n",
        "\n",
        "stack2 = StackingTransformer(pipe_models_2,                   # list of models\n",
        "                               #X_train, y_train, X_test,   # data\n",
        "                               regression=False,           # classification task (if you need \n",
        "                                                           #     regression - set to True)\n",
        "                               #mode='oof_pred',            # mode: oof for train set, fit on full \n",
        "                               variant='A',                            #     train and predict test set once\n",
        "                               needs_proba=True,           # predict probabilities (if you need \n",
        "                                                           #     class labels - set to False) \n",
        "                               ##save_dir='.',               # save result and log in current dir \n",
        "                               #save_dir=save_directory,                                 #     (to disable saving - set to None)\n",
        "                               metric=auc,            # metric: callable\n",
        "                               n_folds=5,                  # number of folds\n",
        "                               stratified=True,            # stratified split for folds\n",
        "                               shuffle=True,               # shuffle the data\n",
        "                               random_state=0,             # ensure reproducibility\n",
        "                               verbose=1)                  # print all info\n",
        "\n",
        "stack3 = StackingTransformer(pipe_models_3,                   # list of models\n",
        "                               #X_train, y_train, X_test,   # data\n",
        "                               regression=False,           # classification task (if you need \n",
        "                                                           #     regression - set to True)\n",
        "                               #mode='oof_pred',            # mode: oof for train set, fit on full \n",
        "                               variant='A',                            #     train and predict test set once\n",
        "                               needs_proba=True,           # predict probabilities (if you need \n",
        "                                                           #     class labels - set to False) \n",
        "                               ##save_dir='.',               # save result and log in current dir \n",
        "                               #save_dir=save_directory,                                 #     (to disable saving - set to None)\n",
        "                               metric=auc,            # metric: callable\n",
        "                               n_folds=5,                  # number of folds\n",
        "                               stratified=True,            # stratified split for folds\n",
        "                               shuffle=True,               # shuffle the data\n",
        "                               random_state=0,             # ensure reproducibility\n",
        "                               verbose=1)                  # print all info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HkNcB1weET_f",
        "colab_type": "code",
        "outputId": "0996f63f-c60d-4667-d597-f0f30e76063f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1827
        }
      },
      "cell_type": "code",
      "source": [
        "# stack1 = stack1.fit(X_train, y_train)\n",
        "# S_train = stack1.transform(X_train)\n",
        "\n",
        "# stack2 = stack2.fit(S_train, y_train)\n",
        "# S_train = stack2.transform(S_train)\n",
        "\n",
        "# stack3 = stack3.fit(S_train, y_train)\n",
        "# S_train = stack3.transform(S_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [auc]\n",
            "variant:      [A]\n",
            "n_estimators: [7]\n",
            "\n",
            "estimator  0: [gnb: GaussianNB]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    MEAN:     [0.88618129] + [0.00408735]\n",
            "\n",
            "estimator  1: [lg: LogisticRegression]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-edf8af80b374>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstack1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mS_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstack2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mS_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vecstack/coresk.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    522\u001b[0m                                            \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                                            \u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                                            transform=self.transform_target)\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0;31m# Predict out-of-fold part of train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vecstack/coresk.py\u001b[0m in \u001b[0;36m_estimator_action\u001b[0;34m(self, estimator, X_train, y_train, X_test, sample_weight, action, transform)\u001b[0m\n\u001b[1;32m    841\u001b[0m                                      sample_weight=sample_weight)\n\u001b[1;32m    842\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'predict'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JKCHbpdZ-818",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stack4 = LogisticRegression(random_state=0)\n",
        "\n",
        "steps = [('stack1', stack1),\n",
        "         ('stack2', stack2),\n",
        "        ('stack3', stack3),\n",
        "        ('stack4', stack4)]\n",
        "\n",
        "# Init Pipeline\n",
        "pipe = Pipeline(steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMTsKY_TApPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1521
        },
        "outputId": "c50c9451-732d-4dc9-aa5f-33cbcc5601f8"
      },
      "cell_type": "code",
      "source": [
        "# Fit\n",
        "pipe = pipe.fit(X_train, y_train)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [auc]\n",
            "variant:      [A]\n",
            "n_estimators: [4]\n",
            "\n",
            "estimator  0: [gnb: GaussianNB]\n",
            "    MEAN:     [0.88928160] + [0.00168644]\n",
            "\n",
            "estimator  1: [xgb: XGBClassifier]\n",
            "    MEAN:     [0.81261512] + [0.00264756]\n",
            "\n",
            "estimator  2: [lgbm: LGBMClassifier]\n",
            "    MEAN:     [0.85238444] + [0.00486554]\n",
            "\n",
            "estimator  3: [cb: CatBoostClassifier]\n",
            "    MEAN:     [0.76248479] + [0.00375792]\n",
            "\n",
            "Train set was detected.\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [gnb: GaussianNB]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [xgb: XGBClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [lgbm: LGBMClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  3: [cb: CatBoostClassifier]\n",
            "    DONE\n",
            "\n",
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [auc]\n",
            "variant:      [A]\n",
            "n_estimators: [3]\n",
            "\n",
            "estimator  0: [xgb: XGBClassifier]\n",
            "    MEAN:     [0.89240256] + [0.00224909]\n",
            "\n",
            "estimator  1: [lgbm: LGBMClassifier]\n",
            "    MEAN:     [0.87233721] + [0.00223194]\n",
            "\n",
            "estimator  2: [cb: CatBoostClassifier]\n",
            "    MEAN:     [0.89135784] + [0.00230937]\n",
            "\n",
            "Train set was detected.\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [xgb: XGBClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [lgbm: LGBMClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [cb: CatBoostClassifier]\n",
            "    DONE\n",
            "\n",
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [auc]\n",
            "variant:      [A]\n",
            "n_estimators: [2]\n",
            "\n",
            "estimator  0: [xgb: XGBClassifier]\n",
            "    MEAN:     [0.89211633] + [0.00213413]\n",
            "\n",
            "estimator  1: [lgbm: LGBMClassifier]\n",
            "    MEAN:     [0.88785981] + [0.00212704]\n",
            "\n",
            "Train set was detected.\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [xgb: XGBClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [lgbm: LGBMClassifier]\n",
            "    DONE\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rqb2dNW2GF9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "64446a73-cbc4-4893-8cab-67a6005bb233"
      },
      "cell_type": "code",
      "source": [
        "y_pred = pipe.predict_proba(X_test)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Final prediction score\n",
        "# print('Final prediction score: %.8f' % log_loss(y_test, y_pred))\n",
        "y_pred_final = [elem[1] for elem in y_pred]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transforming...\n",
            "\n",
            "estimator  0: [gnb: GaussianNB]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [xgb: XGBClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [lgbm: LGBMClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  3: [cb: CatBoostClassifier]\n",
            "    DONE\n",
            "\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [xgb: XGBClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [lgbm: LGBMClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [cb: CatBoostClassifier]\n",
            "    DONE\n",
            "\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [xgb: XGBClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [lgbm: LGBMClassifier]\n",
            "    DONE\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qoQDjTitKwoi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ccf395f6-7aa7-4994-b1b1-d0bd85b74891"
      },
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_test, y_pred_final)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8882629811388479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "MmlMBfQnG4_f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save Pipeline\n",
        "import joblib\n",
        "_ = joblib.dump(pipe, save_directory + 'pipe_with_stack.pkl')\n",
        "# Load Pipeline\n",
        "pipe_loaded = joblib.load(save_directory + 'pipe_with_stack.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfN4T87FDEln",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict on Kaggle Test"
      ]
    },
    {
      "metadata": {
        "id": "J77lgIu7CFuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "9d5de4ff-4abf-48e9-99bc-a4fa1080ca0e"
      },
      "cell_type": "code",
      "source": [
        "kaggle_pred = pipe.predict_proba(test_data_x)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transforming...\n",
            "\n",
            "estimator  0: [gnb: GaussianNB]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [etc: ExtraTreesClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [rfc: RandomForestClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  3: [xgb: XGBClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  4: [lgbm: LGBMClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  5: [cb: CatBoostClassifier]\n",
            "    DONE\n",
            "\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [gnb: GaussianNB]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [xgb: XGBClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [lgbm: LGBMClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  3: [cb: CatBoostClassifier]\n",
            "    DONE\n",
            "\n",
            "Transforming...\n",
            "\n",
            "estimator  0: [xgb: XGBClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  1: [lgbm: LGBMClassifier]\n",
            "    DONE\n",
            "\n",
            "estimator  2: [cb: CatBoostClassifier]\n",
            "    DONE\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OSGFqhE8Cbgr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_df = pd.DataFrame()\n",
        "output_df[\"ID_code\"] = test_data_df[\"ID_code\"]\n",
        "pred_final = [elem[1] for elem in kaggle_pred]\n",
        "output_df[\"target\"] = pred_final\n",
        "output_df.to_csv(save_directory + \"predictions.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oIFHkOA5GY_1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Look at the result"
      ]
    },
    {
      "metadata": {
        "id": "_mF4qZYMGY_5",
        "colab_type": "code",
        "outputId": "12696d42-e7a6-4489-e8e7-2d9db3f9be0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "print('We have %d classes and %d models so in resulting arrays \\\n",
        "we expect to see %d columns.' % (n_classes, len(models_1), n_classes * len(models_1)))\n",
        "print('S_train_1 shape:', S_train_1.shape)\n",
        "print('S_test_1 shape: ', S_test_1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 2 classes and 6 models so in resulting arrays we expect to see 12 columns.\n",
            "S_train_1 shape: (8000, 12)\n",
            "S_test_1 shape:  (2000, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "1Pycd3ftGZAG",
        "colab_type": "code",
        "outputId": "055382b5-c4f4-4bff-fae0-d34eea48c0b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "S_train_1[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.88595608, 0.11404392, 0.87512032, 0.12487968, 0.90076603,\n",
              "        0.09923397, 0.91364649, 0.08635351, 0.86732459, 0.13267542,\n",
              "        0.91284642, 0.08715358],\n",
              "       [0.99596026, 0.00403974, 0.98994982, 0.01005018, 0.90782715,\n",
              "        0.09217285, 0.91324549, 0.08675451, 0.96264553, 0.03735447,\n",
              "        0.96822305, 0.03177695]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "MWVUO6kUGZAX",
        "colab_type": "code",
        "outputId": "79c5b606-4dfd-4b30-f66c-23285136e915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "S_test_1[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.96200187, 0.03799813, 0.94323898, 0.05676102, 0.89576226,\n",
              "        0.10423774, 0.89789474, 0.10210526, 0.92684668, 0.07315334,\n",
              "        0.93933053, 0.06066947],\n",
              "       [0.99292921, 0.00707079, 0.9939683 , 0.0060317 , 0.90598083,\n",
              "        0.09401917, 0.90470871, 0.09529129, 0.95539749, 0.04460249,\n",
              "        0.95137477, 0.04862523]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "NGHPNRwWbLcb",
        "colab_type": "code",
        "outputId": "4dc2d31f-4e7d-4420-ae61-ae9b938b5b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "S_train_1[0][0], S_train_1[0][1], S_train_1[0][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8859560775904103, 0.11404392240959342, 0.11404392240959342)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "XLFcWPbUGZAe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Our arrays and log were saved in current dir"
      ]
    },
    {
      "metadata": {
        "id": "LYLFLXtdGZAi",
        "colab_type": "code",
        "outputId": "5d1c539a-3ecf-4c8e-f5b7-de7a44e746a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "names = sorted(glob(save_directory + '*.npy'))\n",
        "npy_1_name = names[0] # for later use\n",
        "\n",
        "print('Arrays:')\n",
        "for name in names:\n",
        "    print(name)\n",
        "\n",
        "names = sorted(glob(save_directory + '*.log.txt'))\n",
        "log_1_name = names[0] # for later use\n",
        "\n",
        "print('\\nLogs:')\n",
        "for name in names:\n",
        "    print(name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Arrays:\n",
            "/content/gdrive/My Drive/santander_results/[2019.03.26].[04.42.41].477166.c4aa2f.npy\n",
            "\n",
            "Logs:\n",
            "/content/gdrive/My Drive/santander_results/[2019.03.26].[04.42.41].477166.c4aa2f.log.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LQcidKspGZBK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Time to collect results\n",
        "\n",
        "After several (many) days of building, optimizing, and testing models we have a lot of files with saved OOF.  \n",
        "At this point we can load and use OOF of specific model or all OOF we have."
      ]
    },
    {
      "metadata": {
        "id": "a8yNlwH1GZBL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Find specific model\n",
        "\n",
        "We can open logs and find the model of interest.  \n",
        "We can do it programmatically or just open logs in editor.  \n",
        "Name of the `.log.txt` file is the same as the name of corresponding `.npy` file (except extension).  \n",
        "To find columns containing OOF of specific model we use model index from log:\n",
        "* if we predicted class labels - corresponding column index is just model index\n",
        "* if we predicted probabilities - corresponding column index is model index multiplied by number of classes"
      ]
    },
    {
      "metadata": {
        "id": "IhFQcWkbGZBR",
        "colab_type": "code",
        "outputId": "a548740a-f93e-45d5-d96f-96d51e5b6670",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Let's open this log: %s\" % log_1_name)\n",
        "with open(log_1_name) as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "print(\"Let's look what models did we build in those session.\\n\")\n",
        "for line in lines:\n",
        "    if re.search(r'^model [0-9]+', line):\n",
        "        print(line)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's open this log: [2018.02.01].[15.41.41].305268.0eadc0.log.txt\n",
            "Let's look what models did we build in those session.\n",
            "\n",
            "model 0:    [GaussianNB]\n",
            "\n",
            "model 1:    [LogisticRegression]\n",
            "\n",
            "model 2:    [ExtraTreesClassifier]\n",
            "\n",
            "model 3:    [RandomForestClassifier]\n",
            "\n",
            "model 4:    [XGBClassifier]\n",
            "\n",
            "model 5:    [LGBMClassifier]\n",
            "\n",
            "model 6:    [KerasClassifier]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "noWn7uBNGZBh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load specific model OOF\n",
        "\n",
        "Let's say we are interested in `LGBMClassifier`.  \n",
        "We found out that it has index 5.  \n",
        "Then we load target `.npy` file and because of probabilities we need 3 columns from 15 (5 \\* 3) to 18 (5 \\* 3 + 3)"
      ]
    },
    {
      "metadata": {
        "id": "poHXaLPOGZBj",
        "colab_type": "code",
        "outputId": "4b7ee7d1-140e-4f54-bc71-7c50e0d214e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Let's load this .npy file: %s\" % npy_1_name)\n",
        "S = np.load(npy_1_name)\n",
        "S_train_lgbm = S[0][:, 15:18]\n",
        "S_test_lgbm = S[1][:, 15:18]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's load this .npy file: /content/gdrive/My Drive/santander_results/[2019.03.26].[04.42.41].477166.c4aa2f.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WK5YNb_fGZBu",
        "colab_type": "code",
        "outputId": "4346f7fb-9f58-445a-dffd-f1a4a8f2cf3e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "S_train_lgbm[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00040829,  0.00281319,  0.99677852],\n",
              "       [ 0.99732125,  0.00258249,  0.00009626],\n",
              "       [ 0.98322854,  0.01610955,  0.00066191],\n",
              "       [ 0.00107737,  0.99633895,  0.00258368],\n",
              "       [ 0.97101719,  0.02843959,  0.00054321]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "f5soz3_LGZB5",
        "colab_type": "code",
        "outputId": "576b3e46-6653-491b-cd48-a5d84ddc3544",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "S_test_lgbm[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.60639131,  0.3588515 ,  0.03475718],\n",
              "       [ 0.03609523,  0.90174785,  0.06215692],\n",
              "       [ 0.08650007,  0.89717473,  0.0163252 ],\n",
              "       [ 0.00068572,  0.98858075,  0.01073353],\n",
              "       [ 0.00122693,  0.99814513,  0.00062793]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Oiw32ImTGZB_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Compute score of specific model"
      ]
    },
    {
      "metadata": {
        "id": "JtGm0YvLGZCA",
        "colab_type": "code",
        "outputId": "7df706b5-39ec-4c29-8394-160b634ce124",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('LGBMCLassifier log loss: %.8f' % log_loss(y_train, S_train_lgbm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LGBMCLassifier log loss: 0.41430248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "72UtXfCTGZCG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load ALL OOF\n",
        "\n",
        "***Note:*** If you load OOF from scratch, don't forget to load `y_train` from initial dataset too."
      ]
    },
    {
      "metadata": {
        "id": "JDrtmfPoGZCP",
        "colab_type": "code",
        "outputId": "43b0f215-ee84-4cd0-fcef-25c5478829e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "# Create empty arrays\n",
        "S_train_all = np.zeros((X_train.shape[0], 0))\n",
        "S_test_all = np.zeros((X_test.shape[0], 0))\n",
        "\n",
        "# Load results\n",
        "for name in sorted(glob(save_directory + '*.npy')):\n",
        "    print('Loading: %s' % name)\n",
        "    S = np.load(name)\n",
        "    S_train_all = np.c_[S_train_all, S[0]]\n",
        "    S_test_all = np.c_[S_test_all, S[1]]\n",
        "    \n",
        "print('\\nS_train_all shape:', S_train_all.shape)\n",
        "print('S_test_all shape: ', S_test_all.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading: /content/gdrive/My Drive/santander_results/[2019.03.27].[21.14.02].232515.7f0aac.npy\n",
            "\n",
            "S_train_all shape: (8000, 6)\n",
            "S_test_all shape:  (2000, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fpp3rRIjGZCb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Apply 2nd level model"
      ]
    },
    {
      "metadata": {
        "id": "hBK3gZsdexEw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Just use class 0 probability"
      ]
    },
    {
      "metadata": {
        "id": "7Bw6tBH9eMLL",
        "colab_type": "code",
        "outputId": "11c6aa47-997c-44f6-c8ca-6a1aa1efffd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "columns = [n for n in range(0, S_train_all.shape[1], 2)]\n",
        "l2_train = S_train_all[:, columns]\n",
        "l2_test = S_test_all[:, columns]\n",
        "l2_train.shape, l2_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8000, 3), (2000, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "qtxiOpwGGZCb",
        "colab_type": "code",
        "outputId": "6a9b8b26-a839-41ba-d0e1-5f06cc225ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize 2nd level model\n",
        "model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "                      n_estimators=100, max_depth=3)\n",
        "#model = LogisticRegression(random_state=0)\n",
        "    \n",
        "\n",
        "# Fit 2nd level model\n",
        "# model = model.fit(S_train_all, y_train)\n",
        "model = model.fit(l2_train, y_train)\n",
        "\n",
        "\n",
        "# Predict\n",
        "# y_pred = model.predict_proba(S_test_all)\n",
        "y_pred = model.predict_proba(l2_test)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Final prediction score\n",
        "# print('Final prediction score: %.8f' % log_loss(y_test, y_pred))\n",
        "y_pred_final = [elem[1] for elem in y_pred]\n",
        "roc_auc_score(y_test, y_pred_final)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7963757860769392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "VB2dW9VH9fCt",
        "colab_type": "code",
        "outputId": "29491674-795e-4772-f659-373aa88e6d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize 2nd level model\n",
        "#model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "#                      n_estimators=100, max_depth=3)\n",
        "model = LogisticRegression(random_state=0)\n",
        "    \n",
        "\n",
        "# Fit 2nd level model\n",
        "# model = model.fit(S_train_all, y_train)\n",
        "model = model.fit(l2_train, y_train)\n",
        "\n",
        "\n",
        "# Predict\n",
        "# y_pred = model.predict_proba(S_test_all)\n",
        "y_pred = model.predict_proba(l2_test)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Final prediction score\n",
        "# print('Final prediction score: %.8f' % log_loss(y_test, y_pred))\n",
        "y_pred_final = [elem[1] for elem in y_pred]\n",
        "roc_auc_score(y_test, y_pred_final)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7624175376380798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "LRrXb5cMfOkn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "No change with redundant features"
      ]
    },
    {
      "metadata": {
        "id": "cKfBoGm8R4q-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# redundant features test"
      ]
    },
    {
      "metadata": {
        "id": "oC2kEuUZeFrC",
        "colab_type": "code",
        "outputId": "40006c65-328a-4070-c3bf-48eeeca933da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize 2nd level model\n",
        "model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "                      n_estimators=100, max_depth=3)\n",
        "    \n",
        "\n",
        "# Fit 2nd level model\n",
        "model = model.fit(S_train_all, y_train)\n",
        "#model = model.fit(l2_train, y_train)\n",
        "\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict_proba(S_test_all)\n",
        "#y_pred = model.predict_proba(l2_test)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Final prediction score\n",
        "# print('Final prediction score: %.8f' % log_loss(y_test, y_pred))\n",
        "y_pred_final = [elem[1] for elem in y_pred]\n",
        "roc_auc_score(y_test, y_pred_final)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8461037566493023"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "A4_abMa7R6o_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-lPVuCOj-sQn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predictions on the test set"
      ]
    },
    {
      "metadata": {
        "id": "zaXY2Si0-v4e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize 2nd level model\n",
        "#model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "#                      n_estimators=100, max_depth=3)\n",
        "model = LogisticRegression(random_state=0)\n",
        "    \n",
        "\n",
        "# Fit 2nd level model\n",
        "# model = model.fit(S_train_all, y_train)\n",
        "model = model.fit(l2_train, y_train)\n",
        "\n",
        "\n",
        "# Predict\n",
        "# y_pred = model.predict_proba(S_test_all)\n",
        "y_pred = model.predict_proba(l2_test)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Final prediction score\n",
        "# print('Final prediction score: %.8f' % log_loss(y_test, y_pred))\n",
        "y_pred_final = [elem[1] for elem in y_pred]\n",
        "# roc_auc_score(y_test, y_pred_final)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}